{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c21edbf",
   "metadata": {},
   "source": [
    "# Genex Meta-Study Researcher — PDF Folder → Relevance Screen → Evidence Extraction → Scoring → Markdown Evidence Report\n",
    "\n",
    "## What this notebook is\n",
    "This notebook is a **Genex “meta-study researcher” pipeline** that turns a *folder of research-paper PDFs* about a target genetic condition into a structured, ranked **evidence report**.\n",
    "\n",
    "It is designed to:\n",
    "- **screen** papers for relevance to a condition,\n",
    "- **extract** normalized findings (symptoms, treatments, outcomes, genes, definitions) with short evidence snippets,\n",
    "- **aggregate + score** evidence across papers, and\n",
    "- produce a final **Markdown report** suitable for parent-facing summaries or internal Genex knowledge-base drafts.\n",
    "\n",
    "> Output is informational and depends on paper quality/coverage; it is **not medical advice**.\n",
    "\n",
    "---\n",
    "\n",
    "## Inputs (what you must provide)\n",
    "### 1) A folder of PDFs\n",
    "- Set `PAPERS_DIR` to a directory containing paper PDFs (`.pdf`).\n",
    "- The notebook uses **PyMuPDF (`fitz`)** to read text from each PDF.\n",
    "\n",
    "### 2) Target condition string\n",
    "You pass a condition name (e.g., `\"L-serine deficiency disorder\"`) into:\n",
    "- `await run_condition_folder(condition, PAPERS_DIR)`\n",
    "\n",
    "### 3) LLM access (configured in notebook)\n",
    "The pipeline uses **Google ADK** (`LlmAgent`, `Runner`, `InMemorySessionService`) plus an LLM handle (`llm`) for structured JSON extraction and writing.\n",
    "- Make sure the model client is configured and accessible in your environment (API keys / auth as applicable to your ADK setup).\n",
    "\n",
    "---\n",
    "\n",
    "## Process overview (what it does)\n",
    "### A) PDF ingestion\n",
    "- Lists PDFs in `PAPERS_DIR`\n",
    "- Extracts text per paper with PyMuPDF (plus helper utilities for cleaning/metadata as needed)\n",
    "\n",
    "### B) Relevance screening (strict filter)\n",
    "- **Relevance Agent**: given the condition + paper metadata + partial text, returns a **single JSON** `RelevanceDecision`\n",
    "- Only papers marked relevant (with a relevance score) proceed to extraction\n",
    "\n",
    "### C) Structured evidence extraction (per relevant paper)\n",
    "- **Paper Reader Agent** produces a normalized `PaperExtraction` JSON including:\n",
    "  - `summary` + `key_takeaways`\n",
    "  - `findings[]` with items like:\n",
    "    - `category`: symptom | treatment | outcome | population | gene | definition | other\n",
    "    - `polarity`: supports | refutes | mixed | unclear\n",
    "    - `snippet`: ≤2 sentences (evidence)\n",
    "    - `section`: methods | results | discussion | abstract | unknown\n",
    "- A normalization/repair step standardizes fields (e.g., gene names) and safely parses JSON.\n",
    "\n",
    "### D) Aggregation + scoring across papers\n",
    "- Findings are grouped by `(category, name)` and scored using:\n",
    "  - **weighted support** (optional journal/quality weights)\n",
    "  - **supporting paper counts**\n",
    "  - an approximate **90% interval** for support rate (Beta-based heuristic)\n",
    "- Produces `ranked_findings` (symptoms/treatments/genes/definitions/outcomes) sorted by confidence.\n",
    "\n",
    "### E) Final Markdown write-up\n",
    "- **Aggregator/Writer Agent** converts the scored evidence into a **Genex Evidence Report** in Markdown with sections like:\n",
    "  - Executive Summary (bullets)\n",
    "  - Ranked Symptoms (with confidence + interval)\n",
    "  - Ranked Treatments/Interventions (with confidence + interval)\n",
    "  - Outcomes / prognosis (if present)\n",
    "  - Conflicting / uncertain areas\n",
    "  - Limitations + what to read next\n",
    "\n",
    "---\n",
    "\n",
    "## Outputs (what you get)\n",
    "Calling:\n",
    "- `result = await run_condition_folder(\"<condition>\", PAPERS_DIR)`\n",
    "\n",
    "Returns a dictionary that typically includes:\n",
    "- `papers_screened` / `papers_relevant` (counts)\n",
    "- `extractions` (per-paper structured extractions)\n",
    "- `scored` with `ranked_findings` (aggregated evidence)_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63be9e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Python\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "\n",
    "# PDF parsing\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "# Data models\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Google ADK\n",
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.models.lite_llm import LiteLlm\n",
    "from google.genai.types import Content, Part\n",
    "\n",
    "# One session service for this notebook\n",
    "session_service = InMemorySessionService()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9a8ca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# A) Settings\n",
    "# -----------------------\n",
    "PAPERS_DIR = r\"C:/Users/T490/Downloads/Genetics-Dashboard/docs/papers/serine_deficiency_papers/\"\n",
    "MAX_PAGES_PER_PDF = 25            # <-- keep reasonable for context\n",
    "MODEL = \"openai/gpt-4o-mini\"      # <-- or anthropic/..., etc.\n",
    "\n",
    "llm = LiteLlm(model=MODEL)\n",
    "session_service = InMemorySessionService()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "389fb72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# B) Local-only journal reputation weights\n",
    "# -----------------------\n",
    "# 0..1 weight. If a journal isn't present, we fallback to DEFAULT_JOURNAL_WEIGHT.\n",
    "JOURNAL_WEIGHTS = {\n",
    "    \"Pediatrics\": 0.95,\n",
    "    \"The Lancet\": 0.98,\n",
    "    \"NEJM\": 0.99,\n",
    "    \"JAMA\": 0.97,\n",
    "    \"Developmental Medicine & Child Neurology\": 0.90,\n",
    "    \"American Journal of Medical Genetics\": 0.85,\n",
    "}\n",
    "DEFAULT_JOURNAL_WEIGHT = 0.60\n",
    "\n",
    "\n",
    "def journal_weight(journal: Optional[str]) -> float:\n",
    "    if not journal:\n",
    "        return DEFAULT_JOURNAL_WEIGHT\n",
    "    # simple fuzzy match by containment\n",
    "    for k, w in JOURNAL_WEIGHTS.items():\n",
    "        if k.lower() in journal.lower():\n",
    "            return float(w)\n",
    "    return DEFAULT_JOURNAL_WEIGHT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55a79a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# C) PDF reading (local)\n",
    "# -----------------------\n",
    "def list_pdfs(folder: str) -> List[str]:\n",
    "    return sorted(\n",
    "        os.path.join(folder, f)\n",
    "        for f in os.listdir(folder)\n",
    "        if f.lower().endswith(\".pdf\")\n",
    "    )\n",
    "\n",
    "def pdf_to_text(path: str, max_pages: int = 20) -> str:\n",
    "    doc = fitz.open(path)\n",
    "    out = []\n",
    "    for i in range(min(len(doc), max_pages)):\n",
    "        out.append(doc.load_page(i).get_text(\"text\"))\n",
    "    return \"\\n\".join(out)\n",
    "\n",
    "def infer_metadata(path: str, text: str) -> Dict[str, Any]:\n",
    "    filename = os.path.basename(path)\n",
    "    paper_id = filename\n",
    "\n",
    "    # year guess\n",
    "    year = None\n",
    "    m = re.search(r\"\\b(19|20)\\d{2}\\b\", text[:4000])\n",
    "    if m:\n",
    "        year = int(m.group(0))\n",
    "\n",
    "    # title guess: first decent line\n",
    "    title = os.path.splitext(filename)[0]\n",
    "    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]\n",
    "    for ln in lines[:40]:\n",
    "        if 15 < len(ln) < 180 and \"doi\" not in ln.lower():\n",
    "            title = ln\n",
    "            break\n",
    "\n",
    "    # journal guess (very heuristic)\n",
    "    journal = None\n",
    "    jm = re.search(r\"(Journal of [A-Za-z0-9 \\-:&]+)\", text[:8000])\n",
    "    if jm:\n",
    "        journal = jm.group(1).strip()\n",
    "\n",
    "    return {\n",
    "        \"paper_id\": paper_id,\n",
    "        \"path\": path,\n",
    "        \"title\": title,\n",
    "        \"year\": year,\n",
    "        \"journal\": journal,\n",
    "        \"authors\": [],   # <-- add this\n",
    "        \"doi\": None      # <-- optional\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5052b961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Paper-level metadata\n",
    "# -----------------------\n",
    "class PaperMetadata(BaseModel):\n",
    "    title: str\n",
    "    authors: List[str] = Field(default_factory=list)\n",
    "    year: Optional[int] = None\n",
    "    journal: Optional[str] = None\n",
    "    doi: Optional[str] = None\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Relevance decision schema\n",
    "# -----------------------\n",
    "class RelevanceDecision(BaseModel):\n",
    "    paper_id: str\n",
    "    title: str\n",
    "    is_relevant: bool = False\n",
    "    relevance_score: float = 0.0\n",
    "    reason: str = \"\"\n",
    "    matched_terms: List[str] = Field(default_factory=list)\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Extraction schema\n",
    "# -----------------------\n",
    "class ExtractedFinding(BaseModel):\n",
    "    name: str\n",
    "    category: str\n",
    "    polarity: str\n",
    "    snippet: str\n",
    "    section: str\n",
    "\n",
    "\n",
    "class PaperExtraction(BaseModel):\n",
    "    paper_id: str\n",
    "    title: str\n",
    "    authors: List[str] = Field(default_factory=list)   # ← propagated\n",
    "    year: Optional[int] = None\n",
    "    journal: Optional[str] = None\n",
    "    doi: Optional[str] = None\n",
    "    condition: str = \"\"\n",
    "    relevance_score: float = 0.0\n",
    "    findings: List[ExtractedFinding] = Field(default_factory=list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ed67dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a normalize/repair function\n",
    "def normalize_gene_name(name: str) -> str:\n",
    "    return name.strip().upper().replace(\"GENE \", \"\")\n",
    "\n",
    "def normalize_extraction(raw: Dict[str, Any], meta: Dict[str, Any], condition: str, relevance_score: float) -> Dict[str, Any]:\n",
    "    out = {\n",
    "        \"paper_id\": meta[\"paper_id\"],\n",
    "        \"title\": meta[\"title\"],\n",
    "        \"year\": meta.get(\"year\"),\n",
    "        \"journal\": meta.get(\"journal\"),\n",
    "        \"condition\": condition,\n",
    "        \"relevance_score\": float(relevance_score),\n",
    "        \"summary\": \"\",\n",
    "        \"key_takeaways\": [],\n",
    "        \"findings\": [],\n",
    "        \"authors\": meta.get(\"authors\", []),\n",
    "        \"doi\": meta.get(\"doi\"),\n",
    "    }\n",
    "\n",
    "    # ... existing logic that fills out[\"findings\"] ...\n",
    "\n",
    "    # FINAL NORMALIZATION STEP\n",
    "    cleaned_findings = []\n",
    "    for f in out[\"findings\"]:\n",
    "        if not isinstance(f, dict):\n",
    "            continue\n",
    "\n",
    "        if f.get(\"category\") == \"gene\" and f.get(\"name\"):\n",
    "            f[\"name\"] = normalize_gene_name(f[\"name\"])\n",
    "\n",
    "        cleaned_findings.append(f)\n",
    "\n",
    "    out[\"findings\"] = cleaned_findings\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12886b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# E) ADK agent: relevance agent\n",
    "# -----------------------\n",
    "\n",
    "RELEVANCE_SYSTEM = \"\"\"\n",
    "You are a strict biomedical relevance screener.\n",
    "\n",
    "Given:\n",
    "- a target genetic condition (string)\n",
    "- paper metadata + partial text\n",
    "\n",
    "Decide if this paper is relevant to the condition's clinical phenotype, diagnosis, pathophysiology, or treatment.\n",
    "\n",
    "Return ONE JSON object only:\n",
    "{\n",
    "  \"paper_id\": \"...\",\n",
    "  \"title\": \"...\",\n",
    "  \"is_relevant\": true/false,\n",
    "  \"relevance_score\": 0.0-1.0,\n",
    "  \"reason\": \"...\",\n",
    "  \"matched_terms\": [\"...\"]\n",
    "}\n",
    "\n",
    "Rules:\n",
    "- If the paper is about a different disorder, animal model not clearly tied, or generic metabolism without condition link => not relevant.\n",
    "- If it mentions synonyms, gene name(s), biochemical markers, or known treatment of the condition => likely relevant.\n",
    "- Be conservative: false unless there is clear evidence.\n",
    "No markdown fences. JSON only.\n",
    "\"\"\"\n",
    "\n",
    "RELEVANCE_USER = \"\"\"\n",
    "TARGET CONDITION: {condition}\n",
    "\n",
    "PAPER:\n",
    "paper_id: {paper_id}\n",
    "title: {title}\n",
    "\n",
    "TEXT (partial):\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "relevance_agent = LlmAgent(\n",
    "    name=\"PaperRelevanceScreener\",\n",
    "    model=llm,\n",
    "    instruction=RELEVANCE_SYSTEM,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ebc29c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# E) ADK agent: reads one paper\n",
    "# -----------------------\n",
    "READER_SYSTEM = \"\"\"\n",
    "Return ONE valid JSON object ONLY with EXACTLY these keys:\n",
    "{\n",
    "  \"paper_id\": \"...\",\n",
    "  \"title\": \"...\",\n",
    "  \"year\": null,\n",
    "  \"journal\": null,\n",
    "  \"condition\": \"...\",\n",
    "  \"relevance_score\": 0.0,\n",
    "  \"summary\": \"...\",\n",
    "  \"key_takeaways\": [\"...\", \"...\"],\n",
    "  \"findings\": [\n",
    "    {\"name\":\"...\", \"category\":\"symptom|treatment|outcome|population|gene|definition|other\",\n",
    "     \"polarity\":\"supports|refutes|mixed|unclear\",\n",
    "     \"snippet\":\"...\", \"section\":\"methods|results|discussion|abstract|unknown\"}\n",
    "  ]\n",
    "}\n",
    "\n",
    "Rules:\n",
    "- ONLY extract items that relate to the TARGET CONDITION.\n",
    "- Always try to extract:\n",
    "  (A) definition statements about the disorder (category=\"definition\")\n",
    "  (B) genes explicitly mentioned as causal/associated (category=\"gene\"; name must be gene symbol like PHGDH)\n",
    "  (C) symptoms (category=\"symptom\")\n",
    "  (D) treatments/interventions (category=\"treatment\")\n",
    "- If not present in the paper, omit those items (don’t guess).\n",
    "- snippet must be <=2 sentences and clearly support the item.\n",
    "- No markdown fences. No extra keys.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "READER_USER_TEMPLATE = \"\"\"\n",
    "TARGET CONDITION: {condition}\n",
    "\n",
    "PAPER METADATA:\n",
    "paper_id: {paper_id}\n",
    "title: {title}\n",
    "year: {year}\n",
    "journal: {journal}\n",
    "relevance_score: {relevance_score}\n",
    "\n",
    "PAPER TEXT:\n",
    "{text}\n",
    "\n",
    "Return JSON only.\n",
    "\"\"\"\n",
    "paper_reader = LlmAgent(\n",
    "    name=\"PaperReader\",\n",
    "    model=llm,\n",
    "    instruction=READER_SYSTEM,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95e873e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# F) Scoring\n",
    "# -----------------------\n",
    "def beta_interval_90(k: int, n: int) -> Tuple[float, float]:\n",
    "    \"\"\"Approx 90% interval for support rate using Beta(1+k, 1+n-k) normal approximation.\"\"\"\n",
    "    if n <= 0:\n",
    "        return (0.0, 1.0)\n",
    "    a = 1 + k\n",
    "    b = 1 + (n - k)\n",
    "    mean = a / (a + b)\n",
    "    var = (a * b) / (((a + b) ** 2) * (a + b + 1))\n",
    "    sd = math.sqrt(var)\n",
    "    z = 1.645  # ~90%\n",
    "    return (max(0.0, mean - z * sd), min(1.0, mean + z * sd))\n",
    "\n",
    "def aggregate_and_score(extractions: List[PaperExtraction]) -> Dict[str, Any]:\n",
    "    N = len(extractions)\n",
    "    # weights = {p.paper_id: journal_weight(p.journal) for p in extractions}\n",
    "    weights = {\n",
    "    p.paper_id: 0.5 * journal_weight(p.journal) + 0.5 * float(p.relevance_score or 0.0)\n",
    "    for p in extractions\n",
    "    }\n",
    "    total_w = sum(weights.values()) or 1.0\n",
    "\n",
    "    agg: Dict[str, Dict[str, Any]] = {}\n",
    "    supporters: Dict[str, set] = {}\n",
    "\n",
    "    for p in extractions:\n",
    "        w = weights.get(p.paper_id, DEFAULT_JOURNAL_WEIGHT)\n",
    "        for f in p.findings:\n",
    "            key = f\"{f.category}:{f.name}\".lower().strip()\n",
    "            agg.setdefault(key, {\n",
    "                \"category\": f.category,\n",
    "                \"name\": f.name,\n",
    "                \"weighted_support\": 0.0,\n",
    "                \"evidence\": [],\n",
    "                \"snippets\": []\n",
    "            })\n",
    "            supporters.setdefault(key, set())\n",
    "\n",
    "            if f.polarity == \"supports\":\n",
    "                agg[key][\"weighted_support\"] += w\n",
    "                supporters[key].add(p.paper_id)\n",
    "\n",
    "            agg[key][\"evidence\"].append({\n",
    "                \"paper_id\": p.paper_id,\n",
    "                \"title\": p.title,\n",
    "                \"year\": p.year,\n",
    "                \"journal\": p.journal,\n",
    "                \"paper_weight\": round(w, 3),\n",
    "                \"polarity\": f.polarity,\n",
    "                \"section\": f.section,\n",
    "            })\n",
    "            agg[key][\"snippets\"].append(f.snippet)\n",
    "\n",
    "    ranked = []\n",
    "    for key, v in agg.items():\n",
    "        k = len(supporters.get(key, set()))\n",
    "        score = v[\"weighted_support\"] / total_w\n",
    "        lo, hi = beta_interval_90(k, N)\n",
    "        ranked.append({\n",
    "            \"category\": v[\"category\"],\n",
    "            \"name\": v[\"name\"],\n",
    "            \"confidence_score\": round(score, 3),     # weighted\n",
    "            \"supporting_papers\": k,                 # count-based\n",
    "            \"papers_reviewed\": N,\n",
    "            \"cred_interval_90\": [round(lo, 3), round(hi, 3)],\n",
    "            \"example_snippets\": v[\"snippets\"][:3],\n",
    "            \"evidence\": v[\"evidence\"][:8],\n",
    "        })\n",
    "\n",
    "    ranked.sort(key=lambda x: x[\"confidence_score\"], reverse=True)\n",
    "    return {\"ranked_findings\": ranked}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fdc8d64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# G) Aggregator agent (write-up only)\n",
    "# -----------------------\n",
    "AGGREGATOR_SYSTEM = \"\"\"\n",
    "You are the Genex summarization agent.\n",
    "\n",
    "You will receive scored_findings (ranked_findings) derived from papers.\n",
    "Write a report that includes:\n",
    "\n",
    "1) Condition (name)\n",
    "2) Definition (ONLY from findings where category=\"definition\"; if none, say \"Not explicitly defined in the provided papers.\")\n",
    "3) Genes affected (ONLY from category=\"gene\"; list + confidence scores)\n",
    "4) Symptoms (ONLY from category=\"symptom\"; ranked with confidence_score + interval)\n",
    "5) Treatments (ONLY from category=\"treatment\"; ranked with confidence_score + interval)\n",
    "\n",
    "Rules:\n",
    "- Do NOT use any outside knowledge.\n",
    "- If a section has insufficient evidence, say so.\n",
    "- When you list an item, include confidence_score and cred_interval_90.\n",
    "- Use the evidence list to mention which papers support it (paper_id or title).\n",
    "Output Markdown.\n",
    "\"\"\"\n",
    "\n",
    "AGGREGATOR_USER_TEMPLATE = \"\"\"\n",
    "## INPUTS\n",
    "\n",
    "### Papers reviewed (per-paper summaries)\n",
    "{paper_summaries}\n",
    "\n",
    "### Scored evidence JSON\n",
    "{scored_json}\n",
    "\n",
    "## TASK\n",
    "Write the final Genex Evidence Report in Markdown with sections:\n",
    "1) Executive Summary (5-8 bullets)\n",
    "2) Symptoms supported by literature (ranked)\n",
    "3) Treatments/interventions supported by literature (ranked)\n",
    "4) Outcomes / prognosis (if present)\n",
    "5) Conflicting / uncertain areas\n",
    "6) Limitations + what to read next\n",
    "\"\"\"\n",
    "\n",
    "evidence_writer = LlmAgent(\n",
    "    name=\"EvidenceWriter\",\n",
    "    model=llm,\n",
    "    instruction=AGGREGATOR_SYSTEM,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9099b3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "METADATA_SYSTEM = \"\"\"\n",
    "You extract bibliographic metadata from the first page(s) of a biomedical paper.\n",
    "\n",
    "Return ONE valid JSON object ONLY with EXACTLY these keys:\n",
    "{\n",
    "  \"title\": \"...\",\n",
    "  \"authors\": [\"Last, First\", \"...\"],\n",
    "  \"year\": null,\n",
    "  \"journal\": null,\n",
    "  \"doi\": null\n",
    "}\n",
    "\n",
    "Rules:\n",
    "- If unsure, use null (or [] for authors).\n",
    "- Prefer author list as it appears (you can normalize to \"Last, First\" if easy).\n",
    "- Do not hallucinate.\n",
    "\"\"\"\n",
    "\n",
    "metadata_agent = LlmAgent(\n",
    "    name=\"PaperMetadataExtractor\",\n",
    "    model=llm,\n",
    "    instruction=METADATA_SYSTEM,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "517ef035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# H) Main pipeline\n",
    "# -----------------------\n",
    "\n",
    "APP_NAME = \"genex-research\"\n",
    "USER_ID = \"genex\"\n",
    "\n",
    "def extract_last_text(events) -> str:\n",
    "    for e in reversed(events or []):\n",
    "        c = getattr(e, \"content\", None)\n",
    "        if c and getattr(c, \"parts\", None):\n",
    "            for part in c.parts:\n",
    "                t = getattr(part, \"text\", None)\n",
    "                if t:\n",
    "                    return t\n",
    "        if getattr(e, \"text\", None):\n",
    "            return e.text\n",
    "    return \"\"\n",
    "\n",
    "def safe_json_extract(text: str):\n",
    "    \"\"\"\n",
    "    Safely extract a JSON object from an LLM response.\n",
    "    Returns dict if successful, else None.\n",
    "    \"\"\"\n",
    "    if not text or not isinstance(text, str):\n",
    "        return None\n",
    "\n",
    "    # Try direct parse first\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Try to find JSON inside text\n",
    "    match = re.search(r\"\\{[\\s\\S]*\\}\", text)\n",
    "    if match:\n",
    "        try:\n",
    "            return json.loads(match.group(0))\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def safe_json(text: str) -> Dict[str, Any]:\n",
    "    s = text.strip()\n",
    "    if s.startswith(\"```\"):\n",
    "        s = s.strip(\"`\").replace(\"json\", \"\", 1).strip()\n",
    "    # Extract first JSON object if there is stray text\n",
    "    start = s.find(\"{\")\n",
    "    end = s.rfind(\"}\")\n",
    "    if start != -1 and end != -1 and end > start:\n",
    "        s = s[start:end+1]\n",
    "    return json.loads(s)\n",
    "\n",
    "async def run_condition_folder(condition: str, papers_dir: str = PAPERS_DIR) -> Dict[str, Any]:\n",
    "    reader_runner = Runner(app_name=APP_NAME, agent=paper_reader, session_service=session_service)\n",
    "    rel_runner = Runner(app_name=APP_NAME, agent=relevance_agent, session_service=session_service)\n",
    "    writer_runner = Runner(app_name=APP_NAME, agent=evidence_writer, session_service=session_service)\n",
    "\n",
    "    pdfs = list_pdfs(papers_dir)\n",
    "    if not pdfs:\n",
    "        return {\"error\": f\"No PDFs found in {papers_dir}\"}\n",
    "\n",
    "    relevant_extractions: List[PaperExtraction] = []\n",
    "    screened: List[Dict[str, Any]] = []\n",
    "    failures: List[Dict[str, Any]] = []\n",
    "\n",
    "    for i, path in enumerate(pdfs, start=1):\n",
    "        raw_text = pdf_to_text(path, max_pages=MAX_PAGES_PER_PDF)\n",
    "        meta = infer_metadata(path, raw_text[:12000])\n",
    "\n",
    "        meta_text = pdf_to_text(path, max_pages=2)[:60000]\n",
    "\n",
    "        meta_session = f\"meta-{i}-{meta['paper_id']}\"\n",
    "        await session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=meta_session)\n",
    "\n",
    "        meta_runner = Runner(app_name=APP_NAME, agent=metadata_agent, session_service=session_service)\n",
    "\n",
    "        meta_msg = f\"\"\"\n",
    "        PAPER_ID: {meta['paper_id']}\n",
    "        FILENAME: {os.path.basename(path)}\n",
    "\n",
    "        TEXT (first pages):\n",
    "        {meta_text}\n",
    "        \"\"\"\n",
    "        ev0_events = await collect_events(\n",
    "            meta_runner.run_async(\n",
    "                user_id=USER_ID,\n",
    "                session_id=meta_session,\n",
    "                new_message=Content(parts=[Part(text=meta_msg)])\n",
    "            )\n",
    "        )\n",
    "\n",
    "        meta_json = safe_json_extract(extract_last_text(ev0_events))\n",
    "\n",
    "        # Merge LLM metadata into meta (only if present)\n",
    "        if isinstance(meta_json, dict):\n",
    "            meta[\"title\"] = meta_json.get(\"title\") or meta[\"title\"]\n",
    "            meta[\"journal\"] = meta_json.get(\"journal\") or meta[\"journal\"]\n",
    "            meta[\"year\"] = meta_json.get(\"year\") or meta[\"year\"]\n",
    "            meta[\"doi\"] = meta_json.get(\"doi\") or meta.get(\"doi\")\n",
    "            meta[\"authors\"] = meta_json.get(\"authors\") or meta.get(\"authors\", [])\n",
    "\n",
    "\n",
    "        # Create session for screening\n",
    "        screen_session = f\"screen-{i}-{meta['paper_id']}\"\n",
    "        await session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=screen_session)\n",
    "\n",
    "        # ---- 1) Relevance screening on FIRST ~3-5 pages (fast)\n",
    "        screen_text = pdf_to_text(path, max_pages=5)[:60000]\n",
    "        rel_msg = RELEVANCE_USER.format(\n",
    "            condition=condition,\n",
    "            paper_id=meta[\"paper_id\"],\n",
    "            title=meta[\"title\"],\n",
    "            text=screen_text,\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            ev = list(rel_runner.run(\n",
    "                user_id=USER_ID,\n",
    "                session_id=screen_session,\n",
    "                new_message=Content(parts=[Part(text=rel_msg)])\n",
    "            ))\n",
    "            rel_raw = safe_json(extract_last_text(ev))\n",
    "            rel = RelevanceDecision.model_validate({\n",
    "                \"paper_id\": meta[\"paper_id\"],\n",
    "                \"title\": meta[\"title\"],\n",
    "                **rel_raw\n",
    "            })\n",
    "            screened.append(rel.model_dump())\n",
    "\n",
    "            if not rel.is_relevant or rel.relevance_score < 0.55:\n",
    "                print(f\"[{i}/{len(pdfs)}] SKIP (irrelevant): {meta['paper_id']} score={rel.relevance_score:.2f}\")\n",
    "                continue\n",
    "\n",
    "            print(f\"[{i}/{len(pdfs)}] RELEVANT: {meta['paper_id']} score={rel.relevance_score:.2f}\")\n",
    "\n",
    "            # ---- 2) Extraction on more pages (slow)\n",
    "            extract_session = f\"paper-{i}-{meta['paper_id']}\"\n",
    "            await session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=extract_session)\n",
    "\n",
    "            text_for_llm = raw_text[:140000]\n",
    "            user_msg = READER_USER_TEMPLATE.format(\n",
    "                condition=condition,\n",
    "                paper_id=meta[\"paper_id\"],\n",
    "                title=meta[\"title\"],\n",
    "                year=meta.get(\"year\"),\n",
    "                journal=meta.get(\"journal\"),\n",
    "                relevance_score=rel.relevance_score,\n",
    "                text=text_for_llm,\n",
    "            )\n",
    "\n",
    "            ev2 = list(reader_runner.run(\n",
    "                user_id=USER_ID,\n",
    "                session_id=extract_session,\n",
    "                new_message=Content(parts=[Part(text=user_msg)])\n",
    "            ))\n",
    "\n",
    "            obj = safe_json(extract_last_text(ev2))\n",
    "            obj[\"condition\"] = condition\n",
    "            obj[\"relevance_score\"] = float(rel.relevance_score)\n",
    "            # Ensure metadata fallback\n",
    "            obj.setdefault(\"paper_id\", meta[\"paper_id\"])\n",
    "            obj.setdefault(\"title\", meta[\"title\"])\n",
    "            obj.setdefault(\"year\", meta.get(\"year\"))\n",
    "            obj.setdefault(\"journal\", meta.get(\"journal\"))\n",
    "\n",
    "            relevant_extractions.append(PaperExtraction.model_validate(obj))\n",
    "\n",
    "        except Exception as e:\n",
    "            failures.append({\"paper_id\": meta[\"paper_id\"], \"error\": repr(e), \"path\": path})\n",
    "            print(f\"[{i}/{len(pdfs)}] FAILED: {meta['paper_id']} -> {e}\")\n",
    "\n",
    "    if not relevant_extractions:\n",
    "        return {\n",
    "            \"condition\": condition,\n",
    "            \"screened\": screened,\n",
    "            \"failures\": failures,\n",
    "            \"error\": \"No relevant papers after screening.\"\n",
    "        }\n",
    "\n",
    "\n",
    "    # ---- 3) Deterministic scoring on relevant papers only\n",
    "    scored = aggregate_and_score(relevant_extractions)\n",
    "\n",
    "    # ---- 4) Writer report\n",
    "    writer_session = \"final-writeup\"\n",
    "    await session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=writer_session)\n",
    "\n",
    "    paper_summaries = [{\n",
    "        \"paper_id\": p.paper_id,\n",
    "        \"title\": p.title,\n",
    "        \"year\": p.year,\n",
    "        \"journal\": p.journal,\n",
    "        \"relevance_score\": p.relevance_score,\n",
    "        \"summary\": p.summary,\n",
    "        \"key_takeaways\": p.key_takeaways[:6],\n",
    "    } for p in relevant_extractions]\n",
    "\n",
    "    writer_msg = AGGREGATOR_USER_TEMPLATE.format(\n",
    "        paper_summaries=json.dumps(paper_summaries, indent=2),\n",
    "        scored_json=json.dumps({\n",
    "            **scored,\n",
    "            \"condition\": condition,\n",
    "            \"papers_screened\": len(pdfs),\n",
    "            \"papers_relevant\": len(relevant_extractions),\n",
    "        }, indent=2),\n",
    "    )\n",
    "\n",
    "    ev3 = list(writer_runner.run(\n",
    "        user_id=USER_ID,\n",
    "        session_id=writer_session,\n",
    "        new_message=Content(parts=[Part(text=writer_msg)])\n",
    "    ))\n",
    "    report_md = extract_last_text(ev3)\n",
    "\n",
    "    return {\n",
    "        \"condition\": condition,\n",
    "        \"papers_screened\": len(pdfs),\n",
    "        \"papers_relevant\": len(relevant_extractions),\n",
    "        \"screened\": screened,\n",
    "        \"papers\": [p.model_dump() for p in relevant_extractions],\n",
    "        \"scored\": scored,\n",
    "        \"report_markdown\": report_md,\n",
    "        \"failures\": failures,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2da1359",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def collect_events(async_gen):\n",
    "    events = []\n",
    "    async for e in async_gen:\n",
    "        events.append(e)\n",
    "    return events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aaa3d6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/11] RELEVANT: 12534373.pdf score=0.80\n",
      "[2/11] RELEVANT: Bookshelf_NBK592681.pdf score=1.00\n",
      "[3/11] RELEVANT: Human Mutation - 2020 - Abdelfattah - Expanding the genotypic and phenotypic spectrum of severe serine biosynthesis.pdf score=0.95\n",
      "[4/11] RELEVANT: Intl J of Devlp Neuroscience - 2022 - Fu - Mild phenotypes of phosphoglycerate dehydrogenase deficiency by a novel mutation.pdf score=0.85\n",
      "[5/11] RELEVANT: Two new cases of serine deficiency disorders treated with l-serine - PubMed.pdf score=0.90\n",
      "[6/11] RELEVANT: fgene-13-949038.pdf score=0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x000001A0E3637990>\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m run_condition_folder(\u001b[33m\"\u001b[39m\u001b[33mL-serine deficiency disorder\u001b[39m\u001b[33m\"\u001b[39m, PAPERS_DIR)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(result[\u001b[33m\"\u001b[39m\u001b[33mpapers_screened\u001b[39m\u001b[33m\"\u001b[39m], result[\u001b[33m\"\u001b[39m\u001b[33mpapers_relevant\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(result[\u001b[33m\"\u001b[39m\u001b[33mreport_markdown\u001b[39m\u001b[33m\"\u001b[39m][:\u001b[32m1500\u001b[39m])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 87\u001b[39m, in \u001b[36mrun_condition_folder\u001b[39m\u001b[34m(condition, papers_dir)\u001b[39m\n\u001b[32m     78\u001b[39m meta_runner = Runner(app_name=APP_NAME, agent=metadata_agent, session_service=session_service)\n\u001b[32m     80\u001b[39m meta_msg = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[33mPAPER_ID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmeta[\u001b[33m'\u001b[39m\u001b[33mpaper_id\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m     82\u001b[39m \u001b[33mFILENAME: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos.path.basename(path)\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     85\u001b[39m \u001b[33m\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmeta_text\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m     86\u001b[39m \u001b[33m\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m ev0_events = \u001b[38;5;28;01mawait\u001b[39;00m collect_events(\n\u001b[32m     88\u001b[39m     meta_runner.run_async(\n\u001b[32m     89\u001b[39m         user_id=USER_ID,\n\u001b[32m     90\u001b[39m         session_id=meta_session,\n\u001b[32m     91\u001b[39m         new_message=Content(parts=[Part(text=meta_msg)])\n\u001b[32m     92\u001b[39m     )\n\u001b[32m     93\u001b[39m )\n\u001b[32m     95\u001b[39m meta_json = safe_json_extract(extract_last_text(ev0_events))\n\u001b[32m     97\u001b[39m \u001b[38;5;66;03m# Merge LLM metadata into meta (only if present)\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mcollect_events\u001b[39m\u001b[34m(async_gen)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcollect_events\u001b[39m(async_gen):\n\u001b[32m      2\u001b[39m     events = []\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m async_gen:\n\u001b[32m      4\u001b[39m         events.append(e)\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m events\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\adk\\runners.py:472\u001b[39m, in \u001b[36mRunner.run_async\u001b[39m\u001b[34m(self, user_id, session_id, invocation_id, new_message, state_delta, run_config)\u001b[39m\n\u001b[32m    467\u001b[39m       \u001b[38;5;28;01mawait\u001b[39;00m _run_compaction_for_sliding_window(\n\u001b[32m    468\u001b[39m           \u001b[38;5;28mself\u001b[39m.app, session, \u001b[38;5;28mself\u001b[39m.session_service\n\u001b[32m    469\u001b[39m       )\n\u001b[32m    471\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(_run_with_trace(new_message, invocation_id)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    473\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\adk\\runners.py:460\u001b[39m, in \u001b[36mRunner.run_async.<locals>._run_with_trace\u001b[39m\u001b[34m(new_message, invocation_id)\u001b[39m\n\u001b[32m    450\u001b[39m       \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    452\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[32m    453\u001b[39m     \u001b[38;5;28mself\u001b[39m._exec_with_plugin(\n\u001b[32m    454\u001b[39m         invocation_context=invocation_context,\n\u001b[32m   (...)\u001b[39m\u001b[32m    458\u001b[39m     )\n\u001b[32m    459\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    461\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    462\u001b[39m \u001b[38;5;66;03m# Run compaction after all events are yielded from the agent.\u001b[39;00m\n\u001b[32m    463\u001b[39m \u001b[38;5;66;03m# (We don't compact in the middle of an invocation, we only compact at\u001b[39;00m\n\u001b[32m    464\u001b[39m \u001b[38;5;66;03m# the end of an invocation.)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\adk\\runners.py:689\u001b[39m, in \u001b[36mRunner._exec_with_plugin\u001b[39m\u001b[34m(self, invocation_context, session, execute_fn, is_live_call)\u001b[39m\n\u001b[32m    686\u001b[39m is_transcribing: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    688\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(execute_fn(invocation_context)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m689\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    690\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_live_call:\n\u001b[32m    691\u001b[39m       \u001b[38;5;28;01mif\u001b[39;00m event.partial \u001b[38;5;129;01mand\u001b[39;00m _is_transcription(event):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\adk\\runners.py:449\u001b[39m, in \u001b[36mRunner.run_async.<locals>._run_with_trace.<locals>.execute\u001b[39m\u001b[34m(ctx)\u001b[39m\n\u001b[32m    447\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute\u001b[39m(ctx: InvocationContext) -> AsyncGenerator[Event]:\n\u001b[32m    448\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(ctx.agent.run_async(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    450\u001b[39m       \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\adk\\agents\\base_agent.py:294\u001b[39m, in \u001b[36mBaseAgent.run_async\u001b[39m\u001b[34m(self, parent_context)\u001b[39m\n\u001b[32m    291\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    293\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\u001b[38;5;28mself\u001b[39m._run_async_impl(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    295\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ctx.end_invocation:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\adk\\agents\\llm_agent.py:460\u001b[39m, in \u001b[36mLlmAgent._run_async_impl\u001b[39m\u001b[34m(self, ctx)\u001b[39m\n\u001b[32m    458\u001b[39m should_pause = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\u001b[38;5;28mself\u001b[39m._llm_flow.run_async(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    461\u001b[39m     \u001b[38;5;28mself\u001b[39m.__maybe_save_output_to_state(event)\n\u001b[32m    462\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\adk\\flows\\llm_flows\\base_llm_flow.py:370\u001b[39m, in \u001b[36mBaseLlmFlow.run_async\u001b[39m\u001b[34m(self, invocation_context)\u001b[39m\n\u001b[32m    368\u001b[39m last_event = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\u001b[38;5;28mself\u001b[39m._run_one_step_async(invocation_context)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    371\u001b[39m     last_event = event\n\u001b[32m    372\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\adk\\flows\\llm_flows\\base_llm_flow.py:447\u001b[39m, in \u001b[36mBaseLlmFlow._run_one_step_async\u001b[39m\u001b[34m(self, invocation_context)\u001b[39m\n\u001b[32m    436\u001b[39m model_response_event = Event(\n\u001b[32m    437\u001b[39m     \u001b[38;5;28mid\u001b[39m=Event.new_id(),\n\u001b[32m    438\u001b[39m     invocation_id=invocation_context.invocation_id,\n\u001b[32m    439\u001b[39m     author=invocation_context.agent.name,\n\u001b[32m    440\u001b[39m     branch=invocation_context.branch,\n\u001b[32m    441\u001b[39m )\n\u001b[32m    442\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[32m    443\u001b[39m     \u001b[38;5;28mself\u001b[39m._call_llm_async(\n\u001b[32m    444\u001b[39m         invocation_context, llm_request, model_response_event\n\u001b[32m    445\u001b[39m     )\n\u001b[32m    446\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m447\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m llm_response \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    448\u001b[39m     \u001b[38;5;66;03m# Postprocess after calling the LLM.\u001b[39;00m\n\u001b[32m    449\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[32m    450\u001b[39m         \u001b[38;5;28mself\u001b[39m._postprocess_async(\n\u001b[32m    451\u001b[39m             invocation_context,\n\u001b[32m   (...)\u001b[39m\u001b[32m    455\u001b[39m         )\n\u001b[32m    456\u001b[39m     ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m    457\u001b[39m       \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    458\u001b[39m         \u001b[38;5;66;03m# Update the mutable event id to avoid conflict\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\adk\\flows\\llm_flows\\base_llm_flow.py:816\u001b[39m, in \u001b[36mBaseLlmFlow._call_llm_async\u001b[39m\u001b[34m(self, invocation_context, llm_request, model_response_event)\u001b[39m\n\u001b[32m    813\u001b[39m           \u001b[38;5;28;01myield\u001b[39;00m llm_response\n\u001b[32m    815\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(_call_llm_with_tracing()) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m816\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    817\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\adk\\flows\\llm_flows\\base_llm_flow.py:800\u001b[39m, in \u001b[36mBaseLlmFlow._call_llm_async.<locals>._call_llm_with_tracing\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    787\u001b[39m responses_generator = llm.generate_content_async(\n\u001b[32m    788\u001b[39m     llm_request,\n\u001b[32m    789\u001b[39m     stream=invocation_context.run_config.streaming_mode\n\u001b[32m    790\u001b[39m     == StreamingMode.SSE,\n\u001b[32m    791\u001b[39m )\n\u001b[32m    792\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[32m    793\u001b[39m     \u001b[38;5;28mself\u001b[39m._run_and_handle_error(\n\u001b[32m    794\u001b[39m         responses_generator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    798\u001b[39m     )\n\u001b[32m    799\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m800\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m llm_response \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    801\u001b[39m     trace_call_llm(\n\u001b[32m    802\u001b[39m         invocation_context,\n\u001b[32m    803\u001b[39m         model_response_event.id,\n\u001b[32m    804\u001b[39m         llm_request,\n\u001b[32m    805\u001b[39m         llm_response,\n\u001b[32m    806\u001b[39m     )\n\u001b[32m    807\u001b[39m     \u001b[38;5;66;03m# Runs after_model_callback if it exists.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\adk\\flows\\llm_flows\\base_llm_flow.py:1039\u001b[39m, in \u001b[36mBaseLlmFlow._run_and_handle_error\u001b[39m\u001b[34m(self, response_generator, invocation_context, llm_request, model_response_event)\u001b[39m\n\u001b[32m   1037\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1038\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(response_generator) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m-> \u001b[39m\u001b[32m1039\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m   1040\u001b[39m       \u001b[38;5;28;01myield\u001b[39;00m response\n\u001b[32m   1041\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m model_error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\adk\\models\\lite_llm.py:1383\u001b[39m, in \u001b[36mLiteLlm.generate_content_async\u001b[39m\u001b[34m(self, llm_request, stream)\u001b[39m\n\u001b[32m   1380\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m aggregated_llm_response_with_tool_call\n\u001b[32m   1382\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1383\u001b[39m   response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.llm_client.acompletion(**completion_args)\n\u001b[32m   1384\u001b[39m   \u001b[38;5;28;01myield\u001b[39;00m _model_response_to_generate_content_response(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\adk\\models\\lite_llm.py:203\u001b[39m, in \u001b[36mLiteLLMClient.acompletion\u001b[39m\u001b[34m(self, model, messages, tools, **kwargs)\u001b[39m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34macompletion\u001b[39m(\n\u001b[32m    189\u001b[39m     \u001b[38;5;28mself\u001b[39m, model, messages, tools, **kwargs\n\u001b[32m    190\u001b[39m ) -> Union[ModelResponse, CustomStreamWrapper]:\n\u001b[32m    191\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Asynchronously calls acompletion.\u001b[39;00m\n\u001b[32m    192\u001b[39m \n\u001b[32m    193\u001b[39m \u001b[33;03m  Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    200\u001b[39m \u001b[33;03m    The model response as a message.\u001b[39;00m\n\u001b[32m    201\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m acompletion(\n\u001b[32m    204\u001b[39m       model=model,\n\u001b[32m    205\u001b[39m       messages=messages,\n\u001b[32m    206\u001b[39m       tools=tools,\n\u001b[32m    207\u001b[39m       **kwargs,\n\u001b[32m    208\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\litellm\\utils.py:1489\u001b[39m, in \u001b[36mclient.<locals>.wrapper_async\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1486\u001b[39m         print_verbose(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError while checking max token limit: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1488\u001b[39m \u001b[38;5;66;03m# MODEL CALL\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1489\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m original_function(*args, **kwargs)\n\u001b[32m   1490\u001b[39m end_time = datetime.datetime.now()\n\u001b[32m   1491\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _is_streaming_request(\n\u001b[32m   1492\u001b[39m     kwargs=kwargs,\n\u001b[32m   1493\u001b[39m     call_type=call_type,\n\u001b[32m   1494\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\litellm\\main.py:599\u001b[39m, in \u001b[36macompletion\u001b[39m\u001b[34m(model, messages, functions, function_call, timeout, temperature, top_p, n, stream, stream_options, stop, max_tokens, max_completion_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, response_format, seed, tools, tool_choice, parallel_tool_calls, logprobs, top_logprobs, deployment_id, reasoning_effort, verbosity, safety_identifier, service_tier, base_url, api_version, api_key, model_list, extra_headers, thinking, web_search_options, shared_session, **kwargs)\u001b[39m\n\u001b[32m    596\u001b[39m ctx = contextvars.copy_context()\n\u001b[32m    597\u001b[39m func_with_context = partial(ctx.run, func)\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m init_response = \u001b[38;5;28;01mawait\u001b[39;00m loop.run_in_executor(\u001b[38;5;28;01mNone\u001b[39;00m, func_with_context)\n\u001b[32m    600\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(init_response, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    601\u001b[39m     init_response, ModelResponse\n\u001b[32m    602\u001b[39m ):  \u001b[38;5;66;03m## CACHING SCENARIO\u001b[39;00m\n\u001b[32m    603\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(init_response, \u001b[38;5;28mdict\u001b[39m):\n",
      "\u001b[31mCancelledError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "result = await run_condition_folder(\"L-serine deficiency disorder\", PAPERS_DIR)\n",
    "print(result[\"papers_screened\"], result[\"papers_relevant\"])\n",
    "print(result[\"report_markdown\"][:1500])\n",
    "result[\"scored\"][\"ranked_findings\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf4df06",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = result[\"scored\"][\"ranked_findings\"]\n",
    "symptoms = [x for x in rf if x[\"category\"] == \"symptom\"]\n",
    "\n",
    "print(\"Total symptom items:\", len(symptoms))\n",
    "print(\"Top 20 symptoms by score:\")\n",
    "for x in symptoms[:20]:\n",
    "    print(x[\"name\"], x[\"confidence_score\"], x[\"supporting_papers\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4215e792",
   "metadata": {},
   "source": [
    "##Build a searchable “Evidence Index” from your extracted findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b9fa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_evidence_index(papers: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Turns your per-paper extractions into atomic evidence rows that are easy to retrieve.\n",
    "    Each row is one (paper, finding, snippet).\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for p in papers:\n",
    "        for f in (p.get(\"findings\") or []):\n",
    "            rows.append({\n",
    "                \"paper_id\": p.get(\"paper_id\"),\n",
    "                \"title\": p.get(\"title\"),\n",
    "                \"authors\": p.get(\"authors\") or [],\n",
    "                \"year\": p.get(\"year\"),\n",
    "                \"journal\": p.get(\"journal\"),\n",
    "                \"doi\": p.get(\"doi\"),\n",
    "                \"condition\": p.get(\"condition\"),\n",
    "                \"relevance_score\": p.get(\"relevance_score\", 0.0),\n",
    "\n",
    "                \"name\": f.get(\"name\"),\n",
    "                \"category\": f.get(\"category\"),\n",
    "                \"polarity\": f.get(\"polarity\"),\n",
    "                \"section\": f.get(\"section\"),\n",
    "                \"snippet\": f.get(\"snippet\"),\n",
    "            })\n",
    "    return rows\n",
    "\n",
    "\n",
    "def _tokenize(s: str) -> List[str]:\n",
    "    return re.findall(r\"[a-z0-9]+\", (s or \"\").lower())\n",
    "\n",
    "\n",
    "def retrieve_evidence(question: str, evidence_rows: List[Dict[str, Any]], top_k: int = 14) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Lightweight lexical retrieval (no embeddings needed).\n",
    "    Works well because your rows already contain normalized names + snippets.\n",
    "    \"\"\"\n",
    "    qtok = set(_tokenize(question))\n",
    "    if not qtok:\n",
    "        return evidence_rows[:top_k]\n",
    "\n",
    "    scored = []\n",
    "    for r in evidence_rows:\n",
    "        blob = \" \".join([\n",
    "            str(r.get(\"name\",\"\")),\n",
    "            str(r.get(\"category\",\"\")),\n",
    "            str(r.get(\"snippet\",\"\")),\n",
    "            str(r.get(\"title\",\"\")),\n",
    "            str(r.get(\"journal\",\"\")),\n",
    "        ]).lower()\n",
    "\n",
    "        btok = set(_tokenize(blob))\n",
    "        overlap = len(qtok & btok)\n",
    "\n",
    "        # small boosts\n",
    "        boost = 0.0\n",
    "        if r.get(\"polarity\") == \"supports\":\n",
    "            boost += 0.25\n",
    "        boost += 0.15 * float(r.get(\"relevance_score\") or 0.0)\n",
    "\n",
    "        score = overlap + boost\n",
    "        if overlap > 0:\n",
    "            scored.append((score, r))\n",
    "\n",
    "    scored.sort(key=lambda x: x[0], reverse=True)\n",
    "    return [r for _, r in scored[:top_k]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2b7c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the QA agent\n",
    "QA_SYSTEM = \"\"\"\n",
    "You are a biomedical literature Q&A agent.\n",
    "\n",
    "You will be given:\n",
    "- a user question\n",
    "- a set of EVIDENCE ITEMS extracted from papers (each has snippet + citation fields)\n",
    "\n",
    "Your job:\n",
    "- Answer ONLY using the provided evidence items.\n",
    "- If the evidence does not contain an answer, say: \"Not found in the provided papers.\"\n",
    "- Use inline citations like [1], [2] where the numbers correspond to the evidence item IDs.\n",
    "- Prefer \"supports\" polarity evidence, but mention mixed/unclear if present.\n",
    "\n",
    "Output format (Markdown):\n",
    "1) Answer (short, direct)\n",
    "2) Evidence (bullets; each bullet includes a snippet + citation)\n",
    "3) References (numbered; paper title, authors, journal, year; include DOI if present)\n",
    "\n",
    "Do not invent papers, authors, journals, or outcomes.\n",
    "\"\"\"\n",
    "\n",
    "qa_agent = LlmAgent(\n",
    "    name=\"PaperQAAgent\",\n",
    "    model=llm,\n",
    "    instruction=QA_SYSTEM,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314ca339",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def ask_papers(question: str, result: Dict[str, Any], top_k: int = 14) -> str:\n",
    "    \"\"\"\n",
    "    result is the dict returned by run_condition_folder(...)\n",
    "    \"\"\"\n",
    "    papers = result.get(\"papers\") or []\n",
    "    evidence_rows = build_evidence_index(papers)\n",
    "    top = retrieve_evidence(question, evidence_rows, top_k=top_k)\n",
    "\n",
    "    # If nothing retrieved, still give the agent the chance to say \"not found\"\n",
    "    lines = []\n",
    "    for i, r in enumerate(top, start=1):\n",
    "        authors = \", \".join(r.get(\"authors\") or [])\n",
    "        lines.append(\n",
    "            f\"\"\"EVIDENCE_ITEM [{i}]\n",
    "paper_id: {r.get(\"paper_id\")}\n",
    "title: {r.get(\"title\")}\n",
    "authors: {authors if authors else \"UNKNOWN\"}\n",
    "journal: {r.get(\"journal\")}\n",
    "year: {r.get(\"year\")}\n",
    "doi: {r.get(\"doi\")}\n",
    "category: {r.get(\"category\")}\n",
    "name: {r.get(\"name\")}\n",
    "polarity: {r.get(\"polarity\")}\n",
    "section: {r.get(\"section\")}\n",
    "snippet: {r.get(\"snippet\")}\n",
    "\"\"\"\n",
    "        )\n",
    "\n",
    "    qa_context = \"\\n\".join(lines) if lines else \"NO EVIDENCE ITEMS RETRIEVED.\"\n",
    "\n",
    "    qa_session = f\"qa-{re.sub(r'[^a-z0-9]+','-', question.lower())[:40]}\"\n",
    "    await session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=qa_session)\n",
    "\n",
    "    qa_runner = Runner(app_name=APP_NAME, agent=qa_agent, session_service=session_service)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "USER QUESTION:\n",
    "{question}\n",
    "\n",
    "{qa_context}\n",
    "\"\"\"\n",
    "\n",
    "    ev_events = await collect_events(\n",
    "        qa_runner.run_async(\n",
    "            user_id=USER_ID,\n",
    "            session_id=qa_session,\n",
    "            new_message=Content(parts=[Part(text=prompt)])\n",
    "        )\n",
    "    )\n",
    "    return extract_last_text(ev_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7caa90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2) Ask questions against the extracted paper evidence\n",
    "ans1 = await ask_papers(\"Are there different types of serine deficiency?\", result)\n",
    "print(ans1)\n",
    "\n",
    "ans2 = await ask_papers(\"Is there any therapy recommended?\", result)\n",
    "print(ans2)\n",
    "\n",
    "ans3 = await ask_papers(\"Any evidence for L-serine supplementation improving seizures?\", result)\n",
    "print(ans3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GeneX (venv)",
   "language": "python",
   "name": "genex-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
