{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "111400d8",
   "metadata": {},
   "source": [
    "# Genex Research Agents — Multi-Model Therapy Research + Final Parent Summary (ADK Notebook)\n",
    "\n",
    "## What this notebook is\n",
    "This notebook is a **Genex “research agent” prototype** built with **Google ADK (Agent Development Kit)**. It answers parent questions (e.g., “What therapies help?”) by running a **multi-model research pass** (Gemini + GPT + Claude, when keys are available) and then producing **one merged, parent-friendly final summary**.\n",
    "\n",
    "Core idea:\n",
    "- **Profile → Parallel research → Aggregation**\n",
    "- The child’s profile is stored in session state once, then reused across follow-up questions in the same session.\n",
    "\n",
    "> This is educational/supportive content and **not medical advice**.\n",
    "\n",
    "---\n",
    "\n",
    "## Inputs (what you must provide)\n",
    "### 1) API keys (environment variables / `.env`)\n",
    "The notebook initializes clients for:\n",
    "- `GOOGLE_API_KEY` (Gemini via `google.genai` / ADK Gemini wrapper)\n",
    "- `OPENAI_API_KEY` (GPT via `openai`)\n",
    "- `ANTHROPIC_API_KEY` (Claude via `anthropic`)\n",
    "It loads keys via `python-dotenv`.\n",
    "\n",
    "### 2) Parent prompts (runtime)\n",
    "You interact through:\n",
    "- `await ask(\"My child's name is ... age ... diagnosis ...\")`  → stores profile\n",
    "- `await ask(\"What therapies do you recommend for ...?\")`      → triggers research + summary\n",
    "- `await ask(\"More fine-motor activities?\")`                   → follow-up using saved profile\n",
    "\n",
    "---\n",
    "\n",
    "## What it does (process overview)\n",
    "### A) Child profile memory (stateful)\n",
    "- A **Profile Agent** extracts **name / age / diagnosis** from the parent message.\n",
    "- It calls a `save_child_profile` tool to persist the profile in ADK **session state**.\n",
    "- A `retrieve_child_profile` tool is used by downstream agents/tools to ensure the profile exists.\n",
    "\n",
    "### B) Parallel research (multi-model)\n",
    "The notebook defines **model-specific research tools** that:\n",
    "1) read the stored profile from session state  \n",
    "2) craft an age- + diagnosis-specific prompt  \n",
    "3) call the corresponding model (GPT / Claude / Gemini)  \n",
    "4) return structured research notes (or an error if profile is missing)\n",
    "\n",
    "A **ParallelAgent** runs these researchers concurrently so you get broad coverage quickly.\n",
    "\n",
    "### C) Aggregation (single final response)\n",
    "An **Aggregator Agent** merges outputs from the parallel researchers into one coherent deliverable:\n",
    "- organized therapy recommendations (often by domain: gross motor, fine motor, speech, OT/PT, routines, etc.)\n",
    "- practical at-home suggestions\n",
    "- safety/disclaimer language\n",
    "- a single “FINAL SUMMARY” returned via the runner state\n",
    "\n",
    "---\n",
    "\n",
    "## Outputs (what you get)\n",
    "### Console output\n",
    "The helper `ask()` runs the ADK `runner.run_debug(...)` and prints:\n",
    "- `FINAL SUMMARY` (the aggregator’s merged answer)\n",
    "\n",
    "### Session state artifacts (in-memory / persistent depending on session service)\n",
    "Within a single `user_id` + `session_id`, the notebook stores:\n",
    "- `child_profile` (name, age, diagnosis)\n",
    "- the aggregator’s `final_summary`\n",
    "- (optionally) intermediate research outputs, depending on how tools write state\n",
    "\n",
    "> If you restart the kernel or change session ids, the profile may be lost unless you’re using a database-backed session service.\n",
    "\n",
    "---\n",
    "\n",
    "## How to run\n",
    "1) Run cells top-to-bottom to load keys, define tools/agents, and initialize the ADK `Runner`.\n",
    "2) Start with a profile message (required once per session).\n",
    "3) Ask therapy questions; the notebook will reuse the stored profile automatically.\n",
    "\n",
    "---\n",
    "\n",
    "## Limitations / known constraints\n",
    "- If the **profile isn’t stored**, research tools return an error asking for name/age/diagnosis first.\n",
    "- Output quality varies by **model availability** and API access.\n",
    "- This notebook is a **prototype research/summarization pipeline**, not a clinical decision system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87300d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import anthropic\n",
    "import google.genai\n",
    "from google.adk import agents\n",
    "print(\"All good!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d12a3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All API clients initialized successfully.\n",
      "Google: AIzaS\n",
      "OpenAI: sk-pr\n",
      "Anthropic: sk-an\n"
     ]
    }
   ],
   "source": [
    "# Authentication & API clients\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load variables from .env in the project root\n",
    "load_dotenv()\n",
    "\n",
    "# Tell google-genai to use the direct API, not Vertex AI\n",
    "os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"FALSE\"\n",
    "\n",
    "# Optional: read API keys from environment (for sanity checks / debugging)\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "# Initialize OpenAI client\n",
    "from openai import OpenAI\n",
    "openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Initialize Anthropic client\n",
    "from anthropic import Anthropic\n",
    "anthropic_client = Anthropic(api_key=ANTHROPIC_API_KEY)\n",
    "\n",
    "# Safe, short debug prints (won't crash if keys are missing)\n",
    "def _short(key: str | None) -> str:\n",
    "    if not key:\n",
    "        return \"MISSING\"\n",
    "    return key[:5]\n",
    "\n",
    "print(\"All API clients initialized successfully.\")\n",
    "print(\"Google:\", _short(GOOGLE_API_KEY))\n",
    "print(\"OpenAI:\", _short(OPENAI_API_KEY))\n",
    "print(\"Anthropic:\", _short(ANTHROPIC_API_KEY))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ed4fbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports for Genex multi-agent + memory system\n",
    "\n",
    "# ADK agents and orchestration\n",
    "from google.adk.agents import Agent, LlmAgent, SequentialAgent, ParallelAgent\n",
    "\n",
    "# Google LLM wrapper\n",
    "from google.adk.models.google_llm import Gemini\n",
    "\n",
    "# Runners and session services\n",
    "from google.adk.runners import InMemoryRunner, Runner\n",
    "from google.adk.sessions import DatabaseSessionService, InMemorySessionService\n",
    "\n",
    "# Tools + tool context (needed for memory tools)\n",
    "from google.adk.tools import FunctionTool\n",
    "from google.adk.tools.tool_context import ToolContext\n",
    "\n",
    "# App wrapper & compaction config (so sessions persist + are summarized)\n",
    "from google.adk.apps.app import App, EventsCompactionConfig\n",
    "\n",
    "# Low-level Google genai types\n",
    "from google.genai import types\n",
    "\n",
    "# Standard library\n",
    "from typing import Any, Dict\n",
    "import uuid\n",
    "\n",
    "from typing import Any, Dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be0d8909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retry configuration for all Gemini calls (used inside LlmAgent)\n",
    "retry_config = types.HttpRetryOptions(\n",
    "    attempts=5,                 # Max retry attempts\n",
    "    exp_base=7,                 # Exponential backoff base\n",
    "    initial_delay=1,            # Delay before 1st retry\n",
    "    http_status_codes=[429, 500, 503, 504],  # Retry on rate-limit + server errors\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ae3bdd",
   "metadata": {},
   "source": [
    "### Helper Function Save and Retrieve Child's Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c85faf30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Child profile memory tools initialized.\n"
     ]
    }
   ],
   "source": [
    "# CHILD PROFILE MEMORY TOOLS\n",
    "\n",
    "def save_child_profile(\n",
    "    tool_context: ToolContext,\n",
    "    name: str,\n",
    "    age_years: int,\n",
    "    diagnosis: str,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Save the child's profile (e.g., Emma, 3, Down syndrome) into session state.\n",
    "\n",
    "    This is scoped as user-level state, so it can be reused across turns\n",
    "    in the same app/user/session.\n",
    "    \"\"\"\n",
    "    # Normalize inputs a bit\n",
    "    clean_name = name.strip()\n",
    "    clean_diagnosis = diagnosis.strip()\n",
    "\n",
    "    # Use 'user:child:*' prefix for good namespacing\n",
    "    tool_context.state[\"user:child:name\"] = clean_name\n",
    "    tool_context.state[\"user:child:age_years\"] = int(age_years)\n",
    "    tool_context.state[\"user:child:diagnosis\"] = clean_diagnosis\n",
    "\n",
    "    return {\n",
    "        \"status\": \"success\",\n",
    "        \"message\": f\"Stored child profile: {clean_name}, {age_years} years old, diagnosis: {clean_diagnosis}.\",\n",
    "        \"name\": clean_name,\n",
    "        \"age_years\": int(age_years),\n",
    "        \"diagnosis\": clean_diagnosis,\n",
    "    }\n",
    "\n",
    "\n",
    "def retrieve_child_profile(tool_context: ToolContext) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Retrieve the child's profile from session state.\n",
    "\n",
    "    Returns:\n",
    "        {\n",
    "          \"status\": \"success\",\n",
    "          \"name\": ...,\n",
    "          \"age_years\": ...,\n",
    "          \"diagnosis\": ...\n",
    "        }\n",
    "        or\n",
    "        {\n",
    "          \"status\": \"error\",\n",
    "          \"message\": \"...\"\n",
    "        }\n",
    "    \"\"\"\n",
    "    name = tool_context.state.get(\"user:child:name\")\n",
    "    age_years = tool_context.state.get(\"user:child:age_years\")\n",
    "    diagnosis = tool_context.state.get(\"user:child:diagnosis\")\n",
    "\n",
    "    if name is None or age_years is None or diagnosis is None:\n",
    "        return {\n",
    "            \"status\": \"error\",\n",
    "            \"message\": \"Child profile is missing or incomplete. Please provide name, age, and diagnosis.\",\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"status\": \"success\",\n",
    "        \"name\": name,\n",
    "        \"age_years\": age_years,\n",
    "        \"diagnosis\": diagnosis,\n",
    "    }\n",
    "\n",
    "\n",
    "# Wrap as ADK tools so agents can call them\n",
    "save_child_profile_tool = FunctionTool(func=save_child_profile)\n",
    "retrieve_child_profile_tool = FunctionTool(func=retrieve_child_profile)\n",
    "\n",
    "print(\"Child profile memory tools initialized.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7674783",
   "metadata": {},
   "source": [
    "### Profile agent\n",
    "\n",
    "Ensures Emma is in state at the start of the pipeline. We keep a profile agent that stores Emma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6f7e5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_agent = LlmAgent(\n",
    "    name=\"profile_agent\",\n",
    "    model=Gemini(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        retry_options=retry_config,\n",
    "    ),\n",
    "    description=\"Collects and stores child profile info (name, age, diagnosis) in session state.\",\n",
    "    instruction=\"\"\"\n",
    "You are a profile manager for a pediatric support system.\n",
    "\n",
    "Your responsibilities:\n",
    "\n",
    "1. When the user describes their child (name, age, and diagnosis/condition),\n",
    "   you MUST call the `save_child_profile` tool to store those details in session state.\n",
    "\n",
    "2. If the user updates the profile (e.g., new age, additional diagnoses),\n",
    "   call `save_child_profile` again with the updated information.\n",
    "\n",
    "3. After saving, briefly confirm what you stored, for example:\n",
    "   \"I've saved Emma's profile: 3 years old with Down syndrome.\"\n",
    "\n",
    "4. You MAY use `retrieve_child_profile` when you need to:\n",
    "   - check what is currently stored, or\n",
    "   - confirm the existing profile back to the user.\n",
    "\n",
    "5. You MUST NOT:\n",
    "   - give therapy recommendations,\n",
    "   - discuss interventions,\n",
    "   - or provide developmental advice.\n",
    "   Your only job is to manage and confirm the stored profile.\n",
    "\n",
    "All therapy suggestions will be handled by other specialist agents that use this stored profile.\n",
    "\"\"\",\n",
    "    tools=[save_child_profile_tool, retrieve_child_profile_tool],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc39d90",
   "metadata": {},
   "source": [
    "### GPT Research Tool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c4db68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT child research tool initialized.\n"
     ]
    }
   ],
   "source": [
    "def gpt_child_research_tool(tool_context: ToolContext) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Use the stored child profile (name, age, diagnosis) to call GPT-4o-mini\n",
    "    and get age- & diagnosis-specific therapy recommendations for that child.\n",
    "    \"\"\"\n",
    "    # 1) Read Emma's (or any child's) profile from session state\n",
    "    profile = retrieve_child_profile(tool_context)\n",
    "\n",
    "    if profile.get(\"status\") != \"success\":\n",
    "        # Propagate a structured error for the LlmAgent to explain to the user\n",
    "        return {\n",
    "            \"status\": \"error\",\n",
    "            \"error_message\": \"Child profile is missing or incomplete. \"\n",
    "                             \"Please tell me your child's name, age, and diagnosis first.\",\n",
    "        }\n",
    "\n",
    "    name = profile[\"name\"]\n",
    "    age = profile[\"age_years\"]\n",
    "    diagnosis = profile[\"diagnosis\"]\n",
    "\n",
    "    # 2) Build a GPT prompt that is explicitly child- and age-specific\n",
    "    prompt = f\"\"\"\n",
    "You are a pediatric developmental specialist.\n",
    "\n",
    "Child profile:\n",
    "- Name: {name}\n",
    "- Age: {age} years\n",
    "- Diagnosis: {diagnosis}\n",
    "\n",
    "Tasks:\n",
    "1. Give a one-sentence summary of {diagnosis} in the context of a {age}-year-old child.\n",
    "2. Provide recommended therapies tailored SPECIFICALLY for this child's age and condition,\n",
    "   organized under:\n",
    "   - language/communication\n",
    "   - physical/movement\n",
    "   - occupational/fine motor\n",
    "   - social/emotional\n",
    "   - cognitive/learning\n",
    "3. Phrase everything as supportive, practical advice to the parents of {name}.\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        result = openai_client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        )\n",
    "        content = result.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        # Fail gracefully but explicitly so the orchestrator can react\n",
    "        return {\n",
    "            \"status\": \"error\",\n",
    "            \"error_message\": f\"GPT call failed: {e}\",\n",
    "        }\n",
    "\n",
    "    # 3) Return a structured payload for the orchestrating agent\n",
    "    return {\n",
    "        \"status\": \"success\",\n",
    "        \"gpt_research\": content,\n",
    "        \"child_profile_used\": {\n",
    "            \"name\": name,\n",
    "            \"age_years\": age,\n",
    "            \"diagnosis\": diagnosis,\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "# Wrap as ADK tool so LlmAgent can call it\n",
    "gpt_child_tool = FunctionTool(func=gpt_child_research_tool)\n",
    "\n",
    "print(\"GPT child research tool initialized.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68519b3a",
   "metadata": {},
   "source": [
    "### Claude Research Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "274749b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claude child research tool initialized.\n"
     ]
    }
   ],
   "source": [
    "def claude_child_research_tool(tool_context: ToolContext) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Use the stored child profile (name, age, diagnosis) to call Claude\n",
    "    and get age- & diagnosis-specific therapy recommendations.\n",
    "    \"\"\"\n",
    "    # 1) Read child profile from session state\n",
    "    profile = retrieve_child_profile(tool_context)\n",
    "\n",
    "    if profile.get(\"status\") != \"success\":\n",
    "        return {\n",
    "            \"status\": \"error\",\n",
    "            \"error_message\": (\n",
    "                \"Child profile is missing or incomplete. \"\n",
    "                \"Please tell me your child's name, age, and diagnosis first.\"\n",
    "            ),\n",
    "        }\n",
    "\n",
    "    name = profile[\"name\"]\n",
    "    age = profile[\"age_years\"]\n",
    "    diagnosis = profile[\"diagnosis\"]\n",
    "\n",
    "    # 2) Build a Claude prompt tailored to this child\n",
    "    prompt = f\"\"\"\n",
    "You are a pediatric developmental specialist.\n",
    "\n",
    "Child profile:\n",
    "- Name: {name}\n",
    "- Age: {age} years\n",
    "- Diagnosis: {diagnosis}\n",
    "\n",
    "Tasks:\n",
    "1. Give a one-sentence summary of {diagnosis} in the context of a {age}-year-old child.\n",
    "2. Provide recommended therapies tailored SPECIFICALLY for this child's age and condition,\n",
    "   organized under:\n",
    "   - language/communication\n",
    "   - physical/movement\n",
    "   - occupational/fine motor\n",
    "   - social/emotional\n",
    "   - cognitive/learning\n",
    "3. Phrase everything as supportive, concrete advice to the parents of {name}.\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = anthropic_client.messages.create(\n",
    "            model=\"claude-3-5-haiku-20241022\",\n",
    "            max_tokens=700,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        )\n",
    "\n",
    "        # Claude returns a list of content blocks; extract text safely\n",
    "        text_blocks = [\n",
    "            block.text\n",
    "            for block in response.content\n",
    "            if getattr(block, \"type\", None) == \"text\"\n",
    "        ]\n",
    "        claude_text = \"\\n\".join(text_blocks).strip()\n",
    "\n",
    "        if not claude_text:\n",
    "            return {\n",
    "                \"status\": \"error\",\n",
    "                \"error_message\": \"Claude returned no text content.\",\n",
    "            }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"status\": \"error\",\n",
    "            \"error_message\": f\"Claude call failed: {e}\",\n",
    "        }\n",
    "\n",
    "    # 3) Return structured result for the orchestrator / aggregator\n",
    "    return {\n",
    "        \"status\": \"success\",\n",
    "        \"claude_research\": claude_text,\n",
    "        \"child_profile_used\": {\n",
    "            \"name\": name,\n",
    "            \"age_years\": age,\n",
    "            \"diagnosis\": diagnosis,\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "# Wrap this as an ADK FunctionTool so LlmAgents can call it\n",
    "claude_child_tool = FunctionTool(func=claude_child_research_tool)\n",
    "\n",
    "print(\"Claude child research tool initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794edb38",
   "metadata": {},
   "source": [
    "### GPT Research Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0d98c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_researcher = LlmAgent(\n",
    "    name=\"gpt_researcher\",\n",
    "    model=Gemini(\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        retry_options=retry_config\n",
    "    ),\n",
    "    description=\"Researcher agent that personalizes therapy insights using stored child profile.\",\n",
    "    instruction=\"\"\"\n",
    "    You are a pediatric development research agent.\n",
    "    You MUST always call the tool `gpt_child_tool`.\n",
    "\n",
    "    Do NOT generate your own text.\n",
    "    Do NOT summarize or analyze on your own.\n",
    "\n",
    "    Your ONLY job:\n",
    "    - Retrieve the child's profile using the tool_context\n",
    "    - Call gpt_child_research_tool\n",
    "    - Return the tool output as your final answer\n",
    "    \"\"\",\n",
    "    tools=[gpt_child_tool],\n",
    "    output_key=\"gpt_research\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6781fd9",
   "metadata": {},
   "source": [
    "### Claude Research Agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ace1278",
   "metadata": {},
   "outputs": [],
   "source": [
    "claude_researcher = LlmAgent(\n",
    "    name=\"claude_researcher\",\n",
    "    model=Gemini(\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        retry_options=retry_config,\n",
    "    ),\n",
    "    description=\"Researcher agent that personalizes therapy insights using Claude and the stored child profile.\",\n",
    "    instruction=\"\"\"\n",
    "    You are a pediatric development research agent that delegates all content generation to Claude.\n",
    "\n",
    "    You MUST always call the tool `claude_child_tool`.\n",
    "\n",
    "    Rules:\n",
    "    - Do NOT generate your own domain answer.\n",
    "    - Do NOT summarize or rephrase on your own.\n",
    "    - Do NOT answer directly from your own knowledge.\n",
    "    - Your ONLY job is:\n",
    "        1) Use the tool (which already uses the child profile from session state),\n",
    "        2) Return the tool's output as your final answer.\n",
    "    If the tool returns status=\"error\", explain the error_message to the user\n",
    "    and suggest that they provide the child's name, age, and diagnosis.\n",
    "    \"\"\",\n",
    "    tools=[claude_child_tool],\n",
    "    output_key=\"claude_research\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed490bb0",
   "metadata": {},
   "source": [
    "### Gemini Research Agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32d8eb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap retrieve_child_profile as a tool\n",
    "retrieve_child_profile_tool = FunctionTool(func=retrieve_child_profile)\n",
    "\n",
    "gemini_researcher = LlmAgent(\n",
    "    name=\"gemini_researcher\",\n",
    "    model=Gemini(\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        retry_options=retry_config,\n",
    "    ),\n",
    "    description=\"Gemini researcher that personalizes therapy recommendations using saved child profile.\",\n",
    "    instruction=\"\"\"\n",
    "You are a pediatric developmental specialist and part of a multi-model research team.\n",
    "\n",
    "Your REQUIRED behavior:\n",
    "\n",
    "1. Always call the tool `retrieve_child_profile` to retrieve:\n",
    "   - child's name\n",
    "   - child's age (years)\n",
    "   - child's diagnosis/condition\n",
    "\n",
    "2. If the tool returns an error (profile missing):\n",
    "   - Do NOT invent an answer.\n",
    "   - Say: \"I cannot provide recommendations because no child profile is stored yet.\n",
    "     Please provide your child's name, age, and diagnosis.\"\n",
    "\n",
    "3. If the profile exists, produce a personalized research summary:\n",
    "   - Begin with: \"For [NAME], [AGE] years old with [DIAGNOSIS], ...\"\n",
    "   - Provide **therapy recommendations tailored to both age & diagnosis**.\n",
    "   - Organize the recommendations under the exact sections:\n",
    "        • language & communication\n",
    "        • physical & movement\n",
    "        • occupational & fine-motor\n",
    "        • social & emotional\n",
    "        • cognitive & learning\n",
    "\n",
    "4. The tone must be warm, supportive, and parent-focused.\n",
    "5. Keep the response *concise but specific*.\n",
    "6. Do NOT consult external tools or call any API — only use the profile and your own reasoning.\n",
    "\n",
    "Your answer will be stored under the key `gemini_research` and later used by an aggregator.\n",
    "\"\"\",\n",
    "    tools=[retrieve_child_profile_tool],\n",
    "    output_key=\"gemini_research\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a8282d",
   "metadata": {},
   "source": [
    "### Root pipeline\n",
    "#### profile → parallel research → aggregator -> root agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2b668ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline: Parallel Agent\n",
    "parallel_research_team = ParallelAgent(\n",
    "    name=\"parallel_research_team\",\n",
    "    sub_agents=[gemini_researcher, gpt_researcher, claude_researcher],\n",
    ")\n",
    "\n",
    "# pipeline: Aggregator Agent\n",
    "aggregator_agent = LlmAgent(\n",
    "    name=\"aggregator_agent\",\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    tools=[retrieve_child_profile_tool],\n",
    "    description=\"Final summarizer that merges Gemini, GPT, and Claude research into one parent-friendly plan.\",\n",
    "    instruction=\"\"\"\n",
    "You are the final summarizer in a multi-model research system.\n",
    "\n",
    "Upstream agents have already run and stored their outputs in state under these keys\n",
    "(if they succeeded):\n",
    "\n",
    "- 'gemini_research'\n",
    "- 'gpt_research'\n",
    "- 'claude_research'\n",
    "\n",
    "You MUST NOT try to reference them as {gemini_research} or similar; instead, you\n",
    "should conceptually treat them as background sources that the system has already\n",
    "given you.\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Call `retrieve_child_profile` to get:\n",
    "   - child name\n",
    "   - age in years\n",
    "   - diagnosis\n",
    "\n",
    "2. If the profile tool returns an error (no child info stored):\n",
    "   - Do NOT try to summarize.\n",
    "   - Respond with a short, clear message:\n",
    "     \"I can't summarize therapies yet because no child profile is stored.\n",
    "      Please tell me your child's name, age, and diagnosis.\"\n",
    "\n",
    "3. If the profile exists, produce your answer in EXACTLY this structure:\n",
    "\n",
    "   Line 1:\n",
    "     \"[NAME] is [AGE] years old and has [DIAGNOSIS].\"\n",
    "\n",
    "   Line 2:\n",
    "     \" [DIAGNOSIS] is ...\"\n",
    "     → one concise sentence explaining the condition in plain language.\n",
    "\n",
    "   Then a section:\n",
    "\n",
    "   \"Therapy Recommendations by Category\"\n",
    "\n",
    "   Under this, create the following subsections, each with ONE short paragraph\n",
    "   that summarizes what the three researchers broadly agree on:\n",
    "\n",
    "   - **Language & Communication**\n",
    "   - **Physical & Movement**\n",
    "   - **Occupational & Fine Motor**\n",
    "   - **Social & Emotional**\n",
    "   - **Cognitive & Learning**\n",
    "\n",
    "   Use the information from whatever research keys are present in state\n",
    "   (gemini_research, gpt_research, claude_research). If one of them is missing,\n",
    "   just ignore it and rely on the others.\n",
    "\n",
    "4. After that, add a final section:\n",
    "\n",
    "   \"Differences Between Researchers\"\n",
    "\n",
    "   - If they largely agree overall:\n",
    "       Write one short sentence stating that all sources are broadly aligned.\n",
    "   - If there are meaningful differences (e.g., one emphasizes professional services\n",
    "     more while another emphasizes home play-based work), list 2–4 bullet points\n",
    "     describing the key differences.\n",
    "\n",
    "Tone rules:\n",
    "- Warm, supportive, and parent-friendly.\n",
    "- Concise but specific.\n",
    "- No long bullet lists; keep it readable.\n",
    "\"\"\",\n",
    "    output_key=\"final_summary\",\n",
    ")\n",
    "\n",
    "# Pipeline: Root Agent\n",
    "root_agent = SequentialAgent(\n",
    "    name=\"research_system\",\n",
    "    sub_agents=[\n",
    "        profile_agent,          # reads or updates the child profile in state\n",
    "        parallel_research_team, # runs Gemini, GPT, Claude in parallel\n",
    "        aggregator_agent,       # produces the final summary only\n",
    "        ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bd74e6",
   "metadata": {},
   "source": [
    "### Persistent sessions per child / family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47d6eddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genex research app initialized with persistent sessions.\n",
      "   - App name: genex_research_app\n"
     ]
    }
   ],
   "source": [
    "# App & persistence configuration\n",
    "APP_NAME = \"genex_research_app\"\n",
    "USER_ID = \"emma_parents\"\n",
    "\n",
    "# Simple in-memory session service for development\n",
    "session_service = InMemorySessionService()\n",
    "\n",
    "# Define the Genex research app with event compaction\n",
    "research_app = App(\n",
    "    name=APP_NAME,\n",
    "    root_agent=root_agent,   # SequentialAgent: profile → parallel → aggregator\n",
    ")\n",
    "\n",
    "# Runner that ties everything together\n",
    "runner = Runner(\n",
    "    app=research_app,\n",
    "    session_service=session_service,\n",
    ")\n",
    "\n",
    "print(\"Genex research app initialized with persistent sessions.\")\n",
    "print(f\"   - App name: {APP_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "855eef3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "_ResourceExhaustedError",
     "evalue": "\nOn how to mitigate this issue, please refer to:\n\nhttps://google.github.io/adk-docs/agents/models/#error-code-429-resource_exhausted\n\n\n429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 27.173882984s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '27s'}]}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mClientError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\adk\\models\\google_llm.py:211\u001b[39m, in \u001b[36mGemini.generate_content_async\u001b[39m\u001b[34m(self, llm_request, stream)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m   response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.api_client.aio.models.generate_content(\n\u001b[32m    212\u001b[39m       model=llm_request.model,\n\u001b[32m    213\u001b[39m       contents=llm_request.contents,\n\u001b[32m    214\u001b[39m       config=llm_request.config,\n\u001b[32m    215\u001b[39m   )\n\u001b[32m    216\u001b[39m   logger.info(\u001b[33m'\u001b[39m\u001b[33mResponse received from the model.\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\genai\\models.py:7021\u001b[39m, in \u001b[36mAsyncModels.generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   7014\u001b[39m     logger.warning(\n\u001b[32m   7015\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mTools at indices [\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m] are not compatible with automatic function \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   7016\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mcalling (AFC). AFC is disabled. If AFC is intended, please \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   7019\u001b[39m         indices_str,\n\u001b[32m   7020\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m7021\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._generate_content(\n\u001b[32m   7022\u001b[39m       model=model, contents=contents, config=parsed_config\n\u001b[32m   7023\u001b[39m   )\n\u001b[32m   7024\u001b[39m remaining_remote_calls_afc = _extra_utils.get_max_remote_calls_afc(\n\u001b[32m   7025\u001b[39m     parsed_config\n\u001b[32m   7026\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\genai\\models.py:5839\u001b[39m, in \u001b[36mAsyncModels._generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   5837\u001b[39m request_dict = _common.encode_unserializable_types(request_dict)\n\u001b[32m-> \u001b[39m\u001b[32m5839\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._api_client.async_request(\n\u001b[32m   5840\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m'\u001b[39m, path, request_dict, http_options\n\u001b[32m   5841\u001b[39m )\n\u001b[32m   5843\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[32m   5844\u001b[39m     config, \u001b[33m'\u001b[39m\u001b[33mshould_return_http_response\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   5845\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\genai\\_api_client.py:1434\u001b[39m, in \u001b[36mBaseApiClient.async_request\u001b[39m\u001b[34m(self, http_method, path, request_dict, http_options)\u001b[39m\n\u001b[32m   1430\u001b[39m http_request = \u001b[38;5;28mself\u001b[39m._build_request(\n\u001b[32m   1431\u001b[39m     http_method, path, request_dict, http_options\n\u001b[32m   1432\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1434\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._async_request(\n\u001b[32m   1435\u001b[39m     http_request=http_request, http_options=http_options, stream=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1436\u001b[39m )\n\u001b[32m   1437\u001b[39m response_body = result.response_stream[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m result.response_stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\genai\\_api_client.py:1367\u001b[39m, in \u001b[36mBaseApiClient._async_request\u001b[39m\u001b[34m(self, http_request, http_options, stream)\u001b[39m\n\u001b[32m   1366\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m retry(\u001b[38;5;28mself\u001b[39m._async_request_once, http_request, stream)  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1367\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._async_retry(  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[32m   1368\u001b[39m     \u001b[38;5;28mself\u001b[39m._async_request_once, http_request, stream\n\u001b[32m   1369\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py:111\u001b[39m, in \u001b[36mAsyncRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     do = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter(retry_state=retry_state)\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py:153\u001b[39m, in \u001b[36mAsyncRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m action(retry_state)\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\tenacity\\_utils.py:99\u001b[39m, in \u001b[36mwrap_to_async_func.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(*args: typing.Any, **kwargs: typing.Any) -> typing.Any:\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:420\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:187\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m     \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py:114\u001b[39m, in \u001b[36mAsyncRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m fn(*args, **kwargs)\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\genai\\_api_client.py:1312\u001b[39m, in \u001b[36mBaseApiClient._async_request_once\u001b[39m\u001b[34m(self, http_request, stream)\u001b[39m\n\u001b[32m   1304\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._aiohttp_session.request(\n\u001b[32m   1305\u001b[39m     method=http_request.method,\n\u001b[32m   1306\u001b[39m     url=http_request.url,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1310\u001b[39m     **\u001b[38;5;28mself\u001b[39m._async_client_session_request_args,\n\u001b[32m   1311\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1312\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m errors.APIError.raise_for_async_response(response)\n\u001b[32m   1313\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(response.headers, [\u001b[38;5;28;01mawait\u001b[39;00m response.text()])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\genai\\errors.py:188\u001b[39m, in \u001b[36mAPIError.raise_for_async_response\u001b[39m\u001b[34m(cls, response)\u001b[39m\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mUnsupported response type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(response)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m188\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.raise_error_async(status_code, response_json, response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\genai\\errors.py:210\u001b[39m, in \u001b[36mAPIError.raise_error_async\u001b[39m\u001b[34m(cls, status_code, response_json, response)\u001b[39m\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m400\u001b[39m <= status_code < \u001b[32m500\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[32m500\u001b[39m <= status_code < \u001b[32m600\u001b[39m:\n",
      "\u001b[31mClientError\u001b[39m: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 27.173882984s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '27s'}]}}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31m_ResourceExhaustedError\u001b[39m                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# First run (once per session)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m runner.run_debug(\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mEmma. 3 years old, Down syndrome.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      4\u001b[39m     user_id=\u001b[33m\"\u001b[39m\u001b[33memma_parents\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m     session_id=\u001b[33m\"\u001b[39m\u001b[33memma-session-001\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m     quiet=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m      7\u001b[39m     verbose=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m      8\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\adk\\runners.py:1135\u001b[39m, in \u001b[36mRunner.run_debug\u001b[39m\u001b[34m(self, user_messages, user_id, session_id, run_config, quiet, verbose)\u001b[39m\n\u001b[32m   1132\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m quiet:\n\u001b[32m   1133\u001b[39m   \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mUser > \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1135\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.run_async(\n\u001b[32m   1136\u001b[39m     user_id=user_id,\n\u001b[32m   1137\u001b[39m     session_id=session.id,\n\u001b[32m   1138\u001b[39m     new_message=types.UserContent(parts=[types.Part(text=message)]),\n\u001b[32m   1139\u001b[39m     run_config=run_config,\n\u001b[32m   1140\u001b[39m ):\n\u001b[32m   1141\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m quiet:\n\u001b[32m   1142\u001b[39m     print_event(event, verbose=verbose)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\adk\\runners.py:472\u001b[39m, in \u001b[36mRunner.run_async\u001b[39m\u001b[34m(self, user_id, session_id, invocation_id, new_message, state_delta, run_config)\u001b[39m\n\u001b[32m    467\u001b[39m       \u001b[38;5;28;01mawait\u001b[39;00m _run_compaction_for_sliding_window(\n\u001b[32m    468\u001b[39m           \u001b[38;5;28mself\u001b[39m.app, session, \u001b[38;5;28mself\u001b[39m.session_service\n\u001b[32m    469\u001b[39m       )\n\u001b[32m    471\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(_run_with_trace(new_message, invocation_id)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    473\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\adk\\runners.py:460\u001b[39m, in \u001b[36mRunner.run_async.<locals>._run_with_trace\u001b[39m\u001b[34m(new_message, invocation_id)\u001b[39m\n\u001b[32m    450\u001b[39m       \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    452\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[32m    453\u001b[39m     \u001b[38;5;28mself\u001b[39m._exec_with_plugin(\n\u001b[32m    454\u001b[39m         invocation_context=invocation_context,\n\u001b[32m   (...)\u001b[39m\u001b[32m    458\u001b[39m     )\n\u001b[32m    459\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    461\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    462\u001b[39m \u001b[38;5;66;03m# Run compaction after all events are yielded from the agent.\u001b[39;00m\n\u001b[32m    463\u001b[39m \u001b[38;5;66;03m# (We don't compact in the middle of an invocation, we only compact at\u001b[39;00m\n\u001b[32m    464\u001b[39m \u001b[38;5;66;03m# the end of an invocation.)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\adk\\runners.py:689\u001b[39m, in \u001b[36mRunner._exec_with_plugin\u001b[39m\u001b[34m(self, invocation_context, session, execute_fn, is_live_call)\u001b[39m\n\u001b[32m    686\u001b[39m is_transcribing: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    688\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(execute_fn(invocation_context)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m689\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    690\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_live_call:\n\u001b[32m    691\u001b[39m       \u001b[38;5;28;01mif\u001b[39;00m event.partial \u001b[38;5;129;01mand\u001b[39;00m _is_transcription(event):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\adk\\runners.py:449\u001b[39m, in \u001b[36mRunner.run_async.<locals>._run_with_trace.<locals>.execute\u001b[39m\u001b[34m(ctx)\u001b[39m\n\u001b[32m    447\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute\u001b[39m(ctx: InvocationContext) -> AsyncGenerator[Event]:\n\u001b[32m    448\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(ctx.agent.run_async(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    450\u001b[39m       \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\adk\\agents\\base_agent.py:294\u001b[39m, in \u001b[36mBaseAgent.run_async\u001b[39m\u001b[34m(self, parent_context)\u001b[39m\n\u001b[32m    291\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    293\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\u001b[38;5;28mself\u001b[39m._run_async_impl(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    295\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ctx.end_invocation:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\adk\\agents\\sequential_agent.py:77\u001b[39m, in \u001b[36mSequentialAgent._run_async_impl\u001b[39m\u001b[34m(self, ctx)\u001b[39m\n\u001b[32m     74\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_agent_state_event(ctx)\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(sub_agent.run_async(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m     78\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ctx.should_pause_invocation(event):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\adk\\agents\\base_agent.py:294\u001b[39m, in \u001b[36mBaseAgent.run_async\u001b[39m\u001b[34m(self, parent_context)\u001b[39m\n\u001b[32m    291\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    293\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\u001b[38;5;28mself\u001b[39m._run_async_impl(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    295\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ctx.end_invocation:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\adk\\agents\\llm_agent.py:460\u001b[39m, in \u001b[36mLlmAgent._run_async_impl\u001b[39m\u001b[34m(self, ctx)\u001b[39m\n\u001b[32m    458\u001b[39m should_pause = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\u001b[38;5;28mself\u001b[39m._llm_flow.run_async(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    461\u001b[39m     \u001b[38;5;28mself\u001b[39m.__maybe_save_output_to_state(event)\n\u001b[32m    462\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\adk\\flows\\llm_flows\\base_llm_flow.py:370\u001b[39m, in \u001b[36mBaseLlmFlow.run_async\u001b[39m\u001b[34m(self, invocation_context)\u001b[39m\n\u001b[32m    368\u001b[39m last_event = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\u001b[38;5;28mself\u001b[39m._run_one_step_async(invocation_context)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    371\u001b[39m     last_event = event\n\u001b[32m    372\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\adk\\flows\\llm_flows\\base_llm_flow.py:447\u001b[39m, in \u001b[36mBaseLlmFlow._run_one_step_async\u001b[39m\u001b[34m(self, invocation_context)\u001b[39m\n\u001b[32m    436\u001b[39m model_response_event = Event(\n\u001b[32m    437\u001b[39m     \u001b[38;5;28mid\u001b[39m=Event.new_id(),\n\u001b[32m    438\u001b[39m     invocation_id=invocation_context.invocation_id,\n\u001b[32m    439\u001b[39m     author=invocation_context.agent.name,\n\u001b[32m    440\u001b[39m     branch=invocation_context.branch,\n\u001b[32m    441\u001b[39m )\n\u001b[32m    442\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[32m    443\u001b[39m     \u001b[38;5;28mself\u001b[39m._call_llm_async(\n\u001b[32m    444\u001b[39m         invocation_context, llm_request, model_response_event\n\u001b[32m    445\u001b[39m     )\n\u001b[32m    446\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m447\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m llm_response \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    448\u001b[39m     \u001b[38;5;66;03m# Postprocess after calling the LLM.\u001b[39;00m\n\u001b[32m    449\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[32m    450\u001b[39m         \u001b[38;5;28mself\u001b[39m._postprocess_async(\n\u001b[32m    451\u001b[39m             invocation_context,\n\u001b[32m   (...)\u001b[39m\u001b[32m    455\u001b[39m         )\n\u001b[32m    456\u001b[39m     ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m    457\u001b[39m       \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    458\u001b[39m         \u001b[38;5;66;03m# Update the mutable event id to avoid conflict\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\adk\\flows\\llm_flows\\base_llm_flow.py:816\u001b[39m, in \u001b[36mBaseLlmFlow._call_llm_async\u001b[39m\u001b[34m(self, invocation_context, llm_request, model_response_event)\u001b[39m\n\u001b[32m    813\u001b[39m           \u001b[38;5;28;01myield\u001b[39;00m llm_response\n\u001b[32m    815\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(_call_llm_with_tracing()) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m816\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    817\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\adk\\flows\\llm_flows\\base_llm_flow.py:800\u001b[39m, in \u001b[36mBaseLlmFlow._call_llm_async.<locals>._call_llm_with_tracing\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    787\u001b[39m responses_generator = llm.generate_content_async(\n\u001b[32m    788\u001b[39m     llm_request,\n\u001b[32m    789\u001b[39m     stream=invocation_context.run_config.streaming_mode\n\u001b[32m    790\u001b[39m     == StreamingMode.SSE,\n\u001b[32m    791\u001b[39m )\n\u001b[32m    792\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[32m    793\u001b[39m     \u001b[38;5;28mself\u001b[39m._run_and_handle_error(\n\u001b[32m    794\u001b[39m         responses_generator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    798\u001b[39m     )\n\u001b[32m    799\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m800\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m llm_response \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    801\u001b[39m     trace_call_llm(\n\u001b[32m    802\u001b[39m         invocation_context,\n\u001b[32m    803\u001b[39m         model_response_event.id,\n\u001b[32m    804\u001b[39m         llm_request,\n\u001b[32m    805\u001b[39m         llm_response,\n\u001b[32m    806\u001b[39m     )\n\u001b[32m    807\u001b[39m     \u001b[38;5;66;03m# Runs after_model_callback if it exists.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\adk\\flows\\llm_flows\\base_llm_flow.py:1053\u001b[39m, in \u001b[36mBaseLlmFlow._run_and_handle_error\u001b[39m\u001b[34m(self, response_generator, invocation_context, llm_request, model_response_event)\u001b[39m\n\u001b[32m   1051\u001b[39m   \u001b[38;5;28;01myield\u001b[39;00m error_response\n\u001b[32m   1052\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1053\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m model_error\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\adk\\flows\\llm_flows\\base_llm_flow.py:1039\u001b[39m, in \u001b[36mBaseLlmFlow._run_and_handle_error\u001b[39m\u001b[34m(self, response_generator, invocation_context, llm_request, model_response_event)\u001b[39m\n\u001b[32m   1037\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1038\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(response_generator) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m-> \u001b[39m\u001b[32m1039\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m   1040\u001b[39m       \u001b[38;5;28;01myield\u001b[39;00m response\n\u001b[32m   1041\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m model_error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\adk\\models\\google_llm.py:230\u001b[39m, in \u001b[36mGemini.generate_content_async\u001b[39m\u001b[34m(self, llm_request, stream)\u001b[39m\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m ce:\n\u001b[32m    226\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m ce.code == \u001b[32m429\u001b[39m:\n\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# We expect running into a Resource Exhausted error to be a common\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# client error that developers would run into. We enhance the messaging\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;66;03m# with possible fixes to this issue.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m230\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m _ResourceExhaustedError(ce) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mce\u001b[39;00m\n\u001b[32m    232\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ce\n",
      "\u001b[31m_ResourceExhaustedError\u001b[39m: \nOn how to mitigate this issue, please refer to:\n\nhttps://google.github.io/adk-docs/agents/models/#error-code-429-resource_exhausted\n\n\n429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 27.173882984s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '27s'}]}}"
     ]
    }
   ],
   "source": [
    "# First run (once per session)\n",
    "await runner.run_debug(\n",
    "    \"Emma. 3 years old, Down syndrome.\",\n",
    "    user_id=\"emma_parents\",\n",
    "    session_id=\"emma-session-001\",\n",
    "    quiet=True,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1918dba",
   "metadata": {},
   "outputs": [
    {
     "ename": "_ResourceExhaustedError",
     "evalue": "\nOn how to mitigate this issue, please refer to:\n\nhttps://google.github.io/adk-docs/agents/models/#error-code-429-resource_exhausted\n\n\n429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 22.749940455s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '22s'}]}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mClientError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\adk\\models\\google_llm.py:211\u001b[39m, in \u001b[36mGemini.generate_content_async\u001b[39m\u001b[34m(self, llm_request, stream)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m   response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.api_client.aio.models.generate_content(\n\u001b[32m    212\u001b[39m       model=llm_request.model,\n\u001b[32m    213\u001b[39m       contents=llm_request.contents,\n\u001b[32m    214\u001b[39m       config=llm_request.config,\n\u001b[32m    215\u001b[39m   )\n\u001b[32m    216\u001b[39m   logger.info(\u001b[33m'\u001b[39m\u001b[33mResponse received from the model.\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\genai\\models.py:7021\u001b[39m, in \u001b[36mAsyncModels.generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   7014\u001b[39m     logger.warning(\n\u001b[32m   7015\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mTools at indices [\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m] are not compatible with automatic function \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   7016\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mcalling (AFC). AFC is disabled. If AFC is intended, please \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   7019\u001b[39m         indices_str,\n\u001b[32m   7020\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m7021\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._generate_content(\n\u001b[32m   7022\u001b[39m       model=model, contents=contents, config=parsed_config\n\u001b[32m   7023\u001b[39m   )\n\u001b[32m   7024\u001b[39m remaining_remote_calls_afc = _extra_utils.get_max_remote_calls_afc(\n\u001b[32m   7025\u001b[39m     parsed_config\n\u001b[32m   7026\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\genai\\models.py:5839\u001b[39m, in \u001b[36mAsyncModels._generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   5837\u001b[39m request_dict = _common.encode_unserializable_types(request_dict)\n\u001b[32m-> \u001b[39m\u001b[32m5839\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._api_client.async_request(\n\u001b[32m   5840\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m'\u001b[39m, path, request_dict, http_options\n\u001b[32m   5841\u001b[39m )\n\u001b[32m   5843\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[32m   5844\u001b[39m     config, \u001b[33m'\u001b[39m\u001b[33mshould_return_http_response\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   5845\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\genai\\_api_client.py:1434\u001b[39m, in \u001b[36mBaseApiClient.async_request\u001b[39m\u001b[34m(self, http_method, path, request_dict, http_options)\u001b[39m\n\u001b[32m   1430\u001b[39m http_request = \u001b[38;5;28mself\u001b[39m._build_request(\n\u001b[32m   1431\u001b[39m     http_method, path, request_dict, http_options\n\u001b[32m   1432\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1434\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._async_request(\n\u001b[32m   1435\u001b[39m     http_request=http_request, http_options=http_options, stream=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1436\u001b[39m )\n\u001b[32m   1437\u001b[39m response_body = result.response_stream[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m result.response_stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\genai\\_api_client.py:1367\u001b[39m, in \u001b[36mBaseApiClient._async_request\u001b[39m\u001b[34m(self, http_request, http_options, stream)\u001b[39m\n\u001b[32m   1366\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m retry(\u001b[38;5;28mself\u001b[39m._async_request_once, http_request, stream)  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1367\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._async_retry(  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[32m   1368\u001b[39m     \u001b[38;5;28mself\u001b[39m._async_request_once, http_request, stream\n\u001b[32m   1369\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py:111\u001b[39m, in \u001b[36mAsyncRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     do = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter(retry_state=retry_state)\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py:153\u001b[39m, in \u001b[36mAsyncRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m action(retry_state)\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\tenacity\\_utils.py:99\u001b[39m, in \u001b[36mwrap_to_async_func.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(*args: typing.Any, **kwargs: typing.Any) -> typing.Any:\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:420\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:187\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m     \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py:114\u001b[39m, in \u001b[36mAsyncRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m fn(*args, **kwargs)\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\genai\\_api_client.py:1312\u001b[39m, in \u001b[36mBaseApiClient._async_request_once\u001b[39m\u001b[34m(self, http_request, stream)\u001b[39m\n\u001b[32m   1304\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._aiohttp_session.request(\n\u001b[32m   1305\u001b[39m     method=http_request.method,\n\u001b[32m   1306\u001b[39m     url=http_request.url,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1310\u001b[39m     **\u001b[38;5;28mself\u001b[39m._async_client_session_request_args,\n\u001b[32m   1311\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1312\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m errors.APIError.raise_for_async_response(response)\n\u001b[32m   1313\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(response.headers, [\u001b[38;5;28;01mawait\u001b[39;00m response.text()])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\genai\\errors.py:188\u001b[39m, in \u001b[36mAPIError.raise_for_async_response\u001b[39m\u001b[34m(cls, response)\u001b[39m\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mUnsupported response type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(response)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m188\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.raise_error_async(status_code, response_json, response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\genai\\errors.py:210\u001b[39m, in \u001b[36mAPIError.raise_error_async\u001b[39m\u001b[34m(cls, status_code, response_json, response)\u001b[39m\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m400\u001b[39m <= status_code < \u001b[32m500\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[32m500\u001b[39m <= status_code < \u001b[32m600\u001b[39m:\n",
      "\u001b[31mClientError\u001b[39m: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 22.749940455s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '22s'}]}}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31m_ResourceExhaustedError\u001b[39m                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# We can do this instead for the first time running to inspect the final output\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# First-time run: store Emma's profile + generate full research summary\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m response_events = \u001b[38;5;28;01mawait\u001b[39;00m runner.run_debug(\n\u001b[32m      5\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mEmma. 3 years old, Down syndrome.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m     user_id=\u001b[33m\"\u001b[39m\u001b[33memma_parents\u001b[39m\u001b[33m\"\u001b[39m,        \u001b[38;5;66;03m# must match APP_NAME/USER_ID block\u001b[39;00m\n\u001b[32m      7\u001b[39m     session_id=\u001b[33m\"\u001b[39m\u001b[33memma-session-001\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;66;03m# your first persistent session\u001b[39;00m\n\u001b[32m      8\u001b[39m     quiet=\u001b[38;5;28;01mTrue\u001b[39;00m,                    \u001b[38;5;66;03m# prevent noisy output\u001b[39;00m\n\u001b[32m      9\u001b[39m     verbose=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     10\u001b[39m )\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Extract the last event — aggregator output\u001b[39;00m\n\u001b[32m     13\u001b[39m final_event = response_events[-\u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\adk\\runners.py:1135\u001b[39m, in \u001b[36mRunner.run_debug\u001b[39m\u001b[34m(self, user_messages, user_id, session_id, run_config, quiet, verbose)\u001b[39m\n\u001b[32m   1132\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m quiet:\n\u001b[32m   1133\u001b[39m   \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mUser > \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1135\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.run_async(\n\u001b[32m   1136\u001b[39m     user_id=user_id,\n\u001b[32m   1137\u001b[39m     session_id=session.id,\n\u001b[32m   1138\u001b[39m     new_message=types.UserContent(parts=[types.Part(text=message)]),\n\u001b[32m   1139\u001b[39m     run_config=run_config,\n\u001b[32m   1140\u001b[39m ):\n\u001b[32m   1141\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m quiet:\n\u001b[32m   1142\u001b[39m     print_event(event, verbose=verbose)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\adk\\runners.py:472\u001b[39m, in \u001b[36mRunner.run_async\u001b[39m\u001b[34m(self, user_id, session_id, invocation_id, new_message, state_delta, run_config)\u001b[39m\n\u001b[32m    467\u001b[39m       \u001b[38;5;28;01mawait\u001b[39;00m _run_compaction_for_sliding_window(\n\u001b[32m    468\u001b[39m           \u001b[38;5;28mself\u001b[39m.app, session, \u001b[38;5;28mself\u001b[39m.session_service\n\u001b[32m    469\u001b[39m       )\n\u001b[32m    471\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(_run_with_trace(new_message, invocation_id)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    473\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\adk\\runners.py:460\u001b[39m, in \u001b[36mRunner.run_async.<locals>._run_with_trace\u001b[39m\u001b[34m(new_message, invocation_id)\u001b[39m\n\u001b[32m    450\u001b[39m       \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    452\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[32m    453\u001b[39m     \u001b[38;5;28mself\u001b[39m._exec_with_plugin(\n\u001b[32m    454\u001b[39m         invocation_context=invocation_context,\n\u001b[32m   (...)\u001b[39m\u001b[32m    458\u001b[39m     )\n\u001b[32m    459\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    461\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    462\u001b[39m \u001b[38;5;66;03m# Run compaction after all events are yielded from the agent.\u001b[39;00m\n\u001b[32m    463\u001b[39m \u001b[38;5;66;03m# (We don't compact in the middle of an invocation, we only compact at\u001b[39;00m\n\u001b[32m    464\u001b[39m \u001b[38;5;66;03m# the end of an invocation.)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\adk\\runners.py:689\u001b[39m, in \u001b[36mRunner._exec_with_plugin\u001b[39m\u001b[34m(self, invocation_context, session, execute_fn, is_live_call)\u001b[39m\n\u001b[32m    686\u001b[39m is_transcribing: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    688\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(execute_fn(invocation_context)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m689\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    690\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_live_call:\n\u001b[32m    691\u001b[39m       \u001b[38;5;28;01mif\u001b[39;00m event.partial \u001b[38;5;129;01mand\u001b[39;00m _is_transcription(event):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\adk\\runners.py:449\u001b[39m, in \u001b[36mRunner.run_async.<locals>._run_with_trace.<locals>.execute\u001b[39m\u001b[34m(ctx)\u001b[39m\n\u001b[32m    447\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute\u001b[39m(ctx: InvocationContext) -> AsyncGenerator[Event]:\n\u001b[32m    448\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(ctx.agent.run_async(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    450\u001b[39m       \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\adk\\agents\\base_agent.py:294\u001b[39m, in \u001b[36mBaseAgent.run_async\u001b[39m\u001b[34m(self, parent_context)\u001b[39m\n\u001b[32m    291\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    293\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\u001b[38;5;28mself\u001b[39m._run_async_impl(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    295\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ctx.end_invocation:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\adk\\agents\\sequential_agent.py:77\u001b[39m, in \u001b[36mSequentialAgent._run_async_impl\u001b[39m\u001b[34m(self, ctx)\u001b[39m\n\u001b[32m     74\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_agent_state_event(ctx)\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(sub_agent.run_async(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m     78\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ctx.should_pause_invocation(event):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\adk\\agents\\base_agent.py:294\u001b[39m, in \u001b[36mBaseAgent.run_async\u001b[39m\u001b[34m(self, parent_context)\u001b[39m\n\u001b[32m    291\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    293\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\u001b[38;5;28mself\u001b[39m._run_async_impl(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    295\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ctx.end_invocation:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\adk\\agents\\llm_agent.py:460\u001b[39m, in \u001b[36mLlmAgent._run_async_impl\u001b[39m\u001b[34m(self, ctx)\u001b[39m\n\u001b[32m    458\u001b[39m should_pause = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\u001b[38;5;28mself\u001b[39m._llm_flow.run_async(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    461\u001b[39m     \u001b[38;5;28mself\u001b[39m.__maybe_save_output_to_state(event)\n\u001b[32m    462\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\adk\\flows\\llm_flows\\base_llm_flow.py:370\u001b[39m, in \u001b[36mBaseLlmFlow.run_async\u001b[39m\u001b[34m(self, invocation_context)\u001b[39m\n\u001b[32m    368\u001b[39m last_event = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\u001b[38;5;28mself\u001b[39m._run_one_step_async(invocation_context)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    371\u001b[39m     last_event = event\n\u001b[32m    372\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\adk\\flows\\llm_flows\\base_llm_flow.py:447\u001b[39m, in \u001b[36mBaseLlmFlow._run_one_step_async\u001b[39m\u001b[34m(self, invocation_context)\u001b[39m\n\u001b[32m    436\u001b[39m model_response_event = Event(\n\u001b[32m    437\u001b[39m     \u001b[38;5;28mid\u001b[39m=Event.new_id(),\n\u001b[32m    438\u001b[39m     invocation_id=invocation_context.invocation_id,\n\u001b[32m    439\u001b[39m     author=invocation_context.agent.name,\n\u001b[32m    440\u001b[39m     branch=invocation_context.branch,\n\u001b[32m    441\u001b[39m )\n\u001b[32m    442\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[32m    443\u001b[39m     \u001b[38;5;28mself\u001b[39m._call_llm_async(\n\u001b[32m    444\u001b[39m         invocation_context, llm_request, model_response_event\n\u001b[32m    445\u001b[39m     )\n\u001b[32m    446\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m447\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m llm_response \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    448\u001b[39m     \u001b[38;5;66;03m# Postprocess after calling the LLM.\u001b[39;00m\n\u001b[32m    449\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[32m    450\u001b[39m         \u001b[38;5;28mself\u001b[39m._postprocess_async(\n\u001b[32m    451\u001b[39m             invocation_context,\n\u001b[32m   (...)\u001b[39m\u001b[32m    455\u001b[39m         )\n\u001b[32m    456\u001b[39m     ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m    457\u001b[39m       \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    458\u001b[39m         \u001b[38;5;66;03m# Update the mutable event id to avoid conflict\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\adk\\flows\\llm_flows\\base_llm_flow.py:816\u001b[39m, in \u001b[36mBaseLlmFlow._call_llm_async\u001b[39m\u001b[34m(self, invocation_context, llm_request, model_response_event)\u001b[39m\n\u001b[32m    813\u001b[39m           \u001b[38;5;28;01myield\u001b[39;00m llm_response\n\u001b[32m    815\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(_call_llm_with_tracing()) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m816\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    817\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\adk\\flows\\llm_flows\\base_llm_flow.py:800\u001b[39m, in \u001b[36mBaseLlmFlow._call_llm_async.<locals>._call_llm_with_tracing\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    787\u001b[39m responses_generator = llm.generate_content_async(\n\u001b[32m    788\u001b[39m     llm_request,\n\u001b[32m    789\u001b[39m     stream=invocation_context.run_config.streaming_mode\n\u001b[32m    790\u001b[39m     == StreamingMode.SSE,\n\u001b[32m    791\u001b[39m )\n\u001b[32m    792\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[32m    793\u001b[39m     \u001b[38;5;28mself\u001b[39m._run_and_handle_error(\n\u001b[32m    794\u001b[39m         responses_generator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    798\u001b[39m     )\n\u001b[32m    799\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m800\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m llm_response \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    801\u001b[39m     trace_call_llm(\n\u001b[32m    802\u001b[39m         invocation_context,\n\u001b[32m    803\u001b[39m         model_response_event.id,\n\u001b[32m    804\u001b[39m         llm_request,\n\u001b[32m    805\u001b[39m         llm_response,\n\u001b[32m    806\u001b[39m     )\n\u001b[32m    807\u001b[39m     \u001b[38;5;66;03m# Runs after_model_callback if it exists.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\adk\\flows\\llm_flows\\base_llm_flow.py:1053\u001b[39m, in \u001b[36mBaseLlmFlow._run_and_handle_error\u001b[39m\u001b[34m(self, response_generator, invocation_context, llm_request, model_response_event)\u001b[39m\n\u001b[32m   1051\u001b[39m   \u001b[38;5;28;01myield\u001b[39;00m error_response\n\u001b[32m   1052\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1053\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m model_error\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\adk\\flows\\llm_flows\\base_llm_flow.py:1039\u001b[39m, in \u001b[36mBaseLlmFlow._run_and_handle_error\u001b[39m\u001b[34m(self, response_generator, invocation_context, llm_request, model_response_event)\u001b[39m\n\u001b[32m   1037\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1038\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(response_generator) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m-> \u001b[39m\u001b[32m1039\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m   1040\u001b[39m       \u001b[38;5;28;01myield\u001b[39;00m response\n\u001b[32m   1041\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m model_error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T490\\Downloads\\Genetics-Dashboard\\.venv\\Lib\\site-packages\\google\\adk\\models\\google_llm.py:230\u001b[39m, in \u001b[36mGemini.generate_content_async\u001b[39m\u001b[34m(self, llm_request, stream)\u001b[39m\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m ce:\n\u001b[32m    226\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m ce.code == \u001b[32m429\u001b[39m:\n\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# We expect running into a Resource Exhausted error to be a common\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# client error that developers would run into. We enhance the messaging\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;66;03m# with possible fixes to this issue.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m230\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m _ResourceExhaustedError(ce) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mce\u001b[39;00m\n\u001b[32m    232\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ce\n",
      "\u001b[31m_ResourceExhaustedError\u001b[39m: \nOn how to mitigate this issue, please refer to:\n\nhttps://google.github.io/adk-docs/agents/models/#error-code-429-resource_exhausted\n\n\n429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 22.749940455s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '22s'}]}}"
     ]
    }
   ],
   "source": [
    "# We can do this instead for the first time running to inspect the final output\n",
    "\n",
    "# First-time run: store Emma's profile + generate full research summary\n",
    "response_events = await runner.run_debug(\n",
    "    \"Emma. 3 years old, Down syndrome.\",\n",
    "    user_id=\"emma_parents\",        # must match APP_NAME/USER_ID block\n",
    "    session_id=\"emma-session-001\", # your first persistent session\n",
    "    quiet=True,                    # prevent noisy output\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Extract the last event — aggregator output\n",
    "final_event = response_events[-1]\n",
    "\n",
    "# Check whether aggregator emitted a final summary\n",
    "if hasattr(final_event.actions, \"state_delta\") and \"final_summary\" in final_event.actions.state_delta:\n",
    "    final_summary = final_event.actions.state_delta[\"final_summary\"]\n",
    "    print(\"\\n FINAL SUMMARY (Aggregator)\\n\")\n",
    "    print(final_summary)\n",
    "else:\n",
    "    print(\"No final summary produced. Check if aggregator was reached.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982545e5",
   "metadata": {},
   "source": [
    "### Mental model to remember\n",
    "\n",
    "One session = one child context\n",
    "\n",
    "First message must include name + age + diagnosis\n",
    "\n",
    "After that, never repeat it unless it changes\n",
    "\n",
    "Everything else builds on top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da46905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a helper\n",
    "# The helper defines a tiny wrapper so we can type specific questions with await ask\n",
    "# instead of instead of rewriting the full runner call every time.\n",
    "\n",
    "async def ask(prompt: str):\n",
    "    events = await runner.run_debug(\n",
    "        prompt,\n",
    "        user_id=\"emma_parents\",\n",
    "        session_id=\"emma-session-001\",\n",
    "        quiet=True,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    # last event is usually aggregator output\n",
    "    final_event = events[-1]\n",
    "    summary = final_event.actions.state_delta.get(\"final_summary\")\n",
    "\n",
    "    print(\"\\nFINAL SUMMARY\\n\")\n",
    "    print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706465d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "await ask(\"My child's name is Emma. She is 3 years old and has Down syndrome.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4e122f",
   "metadata": {},
   "outputs": [],
   "source": [
    "await ask(\"What therapies do you recommend for Emma's overall development?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5da5cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "await ask(\"Can you suggest more fine-motor activities for Emma?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fb553d",
   "metadata": {},
   "source": [
    "### Summary of the framework\n",
    "\n",
    "[Profile Agent] → stores child:name, age, diagnosis\n",
    "\n",
    "[Parallel Research Team]\n",
    "   - ├── Gemini researcher → Gemini_child_tool → personalized research\n",
    "   - ├── GPT researcher    → GPT_child_tool    → personalized research\n",
    "   - └── Claude researcher → Claude_child_tool → personalized research\n",
    "\n",
    "[Aggregator Agent] → merges 3 sources using child profile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37618b2a",
   "metadata": {},
   "source": [
    "### Summary of the Genex Research Framework (Current State)\n",
    "\n",
    "This framework is a **stateful, multi-agent, multi-model research system** designed to generate **child-specific developmental guidance** in a structured, extensible, and safe way. It cleanly separates *data collection*, *expert research*, and *synthesis*, making it easy to extend later with milestone tracking, developmental-age estimation, and activity planning.\n",
    "\n",
    "---\n",
    "\n",
    "#### 1. Profile Agent — Child Context & Memory\n",
    "**Role:** Establishes and maintains persistent child context across turns.\n",
    "\n",
    "- Extracts the child’s **name, age, and diagnosis/condition** from user messages.\n",
    "- Stores this information in **session state** (memory), scoped to `(user_id, session_id)`.\n",
    "- Enables all downstream agents to operate on a **consistent, shared child profile**.\n",
    "- Does **not** provide therapy guidance or reasoning — its sole responsibility is identity and memory management.\n",
    "\n",
    "> Output:  \n",
    "> `state[\"user:child:name\"]`, `state[\"user:child:age_years\"]`, `state[\"user:child:diagnosis\"]`\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Parallel Research Team — Independent Expert Perspectives\n",
    "**Role:** Gather diverse, independent research perspectives tailored to the child.\n",
    "\n",
    "A `ParallelAgent` runs three specialized researcher agents concurrently:\n",
    "\n",
    "- **Gemini Researcher**\n",
    "  - Retrieves the stored child profile.\n",
    "  - Delegates content generation to Gemini via a tool.\n",
    "  - Produces structured, age- and diagnosis-specific developmental insights.\n",
    "\n",
    "- **GPT Researcher**\n",
    "  - Uses the same stored child profile.\n",
    "  - Calls GPT via a tool for practical, applied recommendations.\n",
    "  - Returns child-specific research output.\n",
    "\n",
    "- **Claude Researcher**\n",
    "  - Also retrieves the child profile.\n",
    "  - Delegates reasoning and narrative generation to Claude.\n",
    "  - Emphasizes clarity, tone, and developmental nuance.\n",
    "\n",
    "Key characteristics:\n",
    "- Researchers **do not communicate with each other**.\n",
    "- No summarization or merging happens at this stage.\n",
    "- Each model’s bias and strengths are preserved intentionally.\n",
    "- All outputs are written to shared state under distinct keys.\n",
    "\n",
    "> Outputs:  \n",
    "> `state[\"gemini_research\"]`  \n",
    "> `state[\"gpt_research\"]`  \n",
    "> `state[\"claude_research\"]`\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Aggregator Agent — Synthesis & Parent-Facing Output\n",
    "**Role:** Convert multi-model research into one coherent, supportive answer.\n",
    "\n",
    "- Re-retrieves the child profile to ground the final message in context.\n",
    "- Reads all available researcher outputs from state.\n",
    "- Synthesizes them into a **single, structured, parent-friendly summary**.\n",
    "- Enforces a consistent format, tone, and level of detail.\n",
    "- Highlights areas of agreement and notes meaningful differences between models.\n",
    "\n",
    "The aggregator is deliberately separated from research so that:\n",
    "- Summarization logic can evolve independently.\n",
    "- Additional research sources can be added later.\n",
    "- Output format remains stable even if models change.\n",
    "\n",
    "> Output:  \n",
    "> `state[\"final_summary\"]`\n",
    "\n",
    "---\n",
    "\n",
    "#### Overall Data & Control Flow\n",
    "\n",
    "- User input\n",
    "- ↓\n",
    "- [Profile Agent] → child profile stored in session state\n",
    "- ↓\n",
    "- [Parallel Research Team]\n",
    "- ├─ Gemini researcher → gemini_research\n",
    "- ├─ GPT researcher → gpt_research\n",
    "- └─ Claude researcher → claude_research\n",
    "- ↓\n",
    "- [Aggregator Agent]\n",
    "- → final_summary (parent-facing response)\n",
    "\n",
    "---\n",
    "\n",
    "#### Why This Architecture Matters\n",
    "\n",
    "- **Personalized:** Every response is tied to a specific child, not a generic condition.\n",
    "- **Robust:** Multiple LLMs reduce single-model bias or failure modes.\n",
    "- **Explainable:** Intermediate research outputs are preserved in state.\n",
    "- **Extensible:** Future pipelines (CDC milestones, developmental age, activity planning) can reuse the same profile memory and aggregation patterns.\n",
    "- **Production-ready:** Clear separation of concerns supports testing, iteration, and scaling.\n",
    "\n",
    "This framework forms the **foundational research layer** of Genex, upon which milestone assessment, therapy planning, and long-term progress tracking will be built."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GeneX (venv)",
   "language": "python",
   "name": "genex-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
