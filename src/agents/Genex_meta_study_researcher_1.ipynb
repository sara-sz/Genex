{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "547a0888",
   "metadata": {},
   "source": [
    "# Genex Meta-Study Researcher (v3 — Evidence Synthesis Report + Q&A)\n",
    "\n",
    "This version adds a **Report Synthesis Agent** so `result[\"report_markdown\"]` becomes a clinician-style evidence synthesis (not a raw snippet dump), while keeping your evidence-grounded Q&A agent.\n",
    "\n",
    "## Output report structure\n",
    "1) Executive Summary including definition and genes affected  \n",
    "2) Symptoms supported by literature (ranked)  \n",
    "3) Treatments/interventions supported by literature (ranked)  \n",
    "4) Outcomes / prognosis (if present)  \n",
    "5) Conflicting / uncertain areas  \n",
    "6) Limitations + what to read next  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf8f8820",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------\n",
    "# 0) Imports\n",
    "# -----------------------\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "import fitz  # PyMuPDF\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "import uuid\n",
    "\n",
    "# Google ADK\n",
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.models.lite_llm import LiteLlm\n",
    "\n",
    "# Optional GenAI message types (depends on installed package)\n",
    "try:\n",
    "    from google.genai.types import Content, Part\n",
    "    _HAS_GENAI_TYPES = True\n",
    "except Exception:\n",
    "    Content, Part = None, None\n",
    "    _HAS_GENAI_TYPES = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dacc067c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------\n",
    "# 1) Settings\n",
    "# -----------------------\n",
    "# TODO: change this to your local folder containing PDFs\n",
    "PAPERS_DIR = r\"C:/Users/T490/Downloads/Genex/docs/papers/serine_deficiency_papers\"\n",
    "\n",
    "MAX_PAGES_PER_PDF = 25\n",
    "\n",
    "# LiteLLM-compatible model id\n",
    "MODEL = \"openai/gpt-4o-mini\"\n",
    "\n",
    "APP_NAME = \"genex_meta_study\"\n",
    "USER_ID = \"genex_user\"\n",
    "\n",
    "llm = LiteLlm(model=MODEL)\n",
    "session_service = InMemorySessionService()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a20a1d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------\n",
    "# 2) Schemas\n",
    "# -----------------------\n",
    "class PaperMetadata(BaseModel):\n",
    "    title: str\n",
    "    authors: List[str] = Field(default_factory=list)\n",
    "    year: Optional[int] = None\n",
    "    journal: Optional[str] = None\n",
    "    doi: Optional[str] = None\n",
    "\n",
    "class RelevanceDecision(BaseModel):\n",
    "    paper_id: str\n",
    "    title: str\n",
    "    is_relevant: bool = False\n",
    "    relevance_score: float = 0.0  # 0..1\n",
    "    reason: str = \"\"\n",
    "    matched_terms: List[str] = Field(default_factory=list)\n",
    "\n",
    "class ExtractedFinding(BaseModel):\n",
    "    name: str = Field(..., description=\"Normalized term\")\n",
    "    category: str = Field(..., description=\"definition|gene|symptom|treatment|outcome|population|other\")\n",
    "    polarity: str = Field(..., description=\"supports|refutes|mixed|unclear\")\n",
    "    snippet: str = Field(..., description=\"<=2 sentences evidence snippet\")\n",
    "    section: str = Field(..., description=\"methods|results|discussion|abstract|unknown\")\n",
    "\n",
    "class PaperExtraction(BaseModel):\n",
    "    paper_id: str\n",
    "    title: str\n",
    "    authors: List[str] = Field(default_factory=list)\n",
    "    year: Optional[int] = None\n",
    "    journal: Optional[str] = None\n",
    "    doi: Optional[str] = None\n",
    "\n",
    "    condition: str = \"\"\n",
    "    relevance_score: float = 0.0\n",
    "    summary: str = \"\"\n",
    "    key_takeaways: List[str] = Field(default_factory=list)\n",
    "    findings: List[ExtractedFinding] = Field(default_factory=list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c628effd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------\n",
    "# 3) Helper utilities (robust across ADK versions)\n",
    "# -----------------------\n",
    "def list_pdfs(folder: str) -> List[str]:\n",
    "    return sorted(\n",
    "        os.path.join(folder, f)\n",
    "        for f in os.listdir(folder)\n",
    "        if f.lower().endswith(\".pdf\")\n",
    "    )\n",
    "\n",
    "def pdf_to_text(path: str, max_pages: int = 20) -> str:\n",
    "    doc = fitz.open(path)\n",
    "    out = []\n",
    "    for i in range(min(len(doc), max_pages)):\n",
    "        out.append(doc.load_page(i).get_text(\"text\"))\n",
    "    doc.close()\n",
    "    return \"\\n\".join(out)\n",
    "\n",
    "def safe_json_extract(text: str) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"Extract a JSON object from model output. Returns dict or None.\"\"\"\n",
    "    if not text or not isinstance(text, str):\n",
    "        return None\n",
    "    text = text.strip()\n",
    "\n",
    "    try:\n",
    "        obj = json.loads(text)\n",
    "        if isinstance(obj, dict):\n",
    "            return obj\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    fence = re.search(r\"```json\\s*(\\{[\\s\\S]*?\\})\\s*```\", text, flags=re.IGNORECASE)\n",
    "    if fence:\n",
    "        try:\n",
    "            obj = json.loads(fence.group(1))\n",
    "            if isinstance(obj, dict):\n",
    "                return obj\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    m = re.search(r\"(\\{[\\s\\S]*\\})\", text)\n",
    "    if m:\n",
    "        try:\n",
    "            obj = json.loads(m.group(1))\n",
    "            if isinstance(obj, dict):\n",
    "                return obj\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    return None\n",
    "\n",
    "def _make_message(text: str):\n",
    "    \"\"\"Create ADK message payload in a version-tolerant way.\"\"\"\n",
    "    if _HAS_GENAI_TYPES and Content is not None and Part is not None:\n",
    "        return Content(parts=[Part(text=text)])\n",
    "    return text\n",
    "\n",
    "async def collect_events(async_gen) -> List[Any]:\n",
    "    events = []\n",
    "    async for e in async_gen:\n",
    "        events.append(e)\n",
    "    return events\n",
    "\n",
    "async def run_runner(runner: Runner, user_id: str, session_id: str, text: str) -> List[Any]:\n",
    "    \"\"\"Run ADK runner in a way that works for both streaming and non-streaming.\"\"\"\n",
    "    res = runner.run_async(user_id=user_id, session_id=session_id, new_message=_make_message(text))\n",
    "    if hasattr(res, \"__aiter__\"):\n",
    "        return await collect_events(res)\n",
    "    out = await res\n",
    "    if isinstance(out, list):\n",
    "        return out\n",
    "    return [out]\n",
    "\n",
    "def _event_to_text(e: Any) -> str:\n",
    "    if e is None:\n",
    "        return \"\"\n",
    "    if isinstance(e, str):\n",
    "        return e\n",
    "    if isinstance(e, dict):\n",
    "        for k in (\"text\", \"output_text\"):\n",
    "            v = e.get(k)\n",
    "            if isinstance(v, str):\n",
    "                return v\n",
    "        content = e.get(\"content\")\n",
    "        if isinstance(content, dict):\n",
    "            parts = content.get(\"parts\") or []\n",
    "            texts = []\n",
    "            for p in parts:\n",
    "                if isinstance(p, dict) and isinstance(p.get(\"text\"), str):\n",
    "                    texts.append(p[\"text\"])\n",
    "            return \"\\n\".join(texts)\n",
    "\n",
    "    for attr in (\"text\", \"output_text\"):\n",
    "        if hasattr(e, attr):\n",
    "            v = getattr(e, attr)\n",
    "            if isinstance(v, str):\n",
    "                return v\n",
    "\n",
    "    if hasattr(e, \"content\"):\n",
    "        c = getattr(e, \"content\")\n",
    "        if hasattr(c, \"parts\"):\n",
    "            parts = getattr(c, \"parts\") or []\n",
    "            texts = []\n",
    "            for p in parts:\n",
    "                if hasattr(p, \"text\") and isinstance(getattr(p, \"text\"), str):\n",
    "                    texts.append(getattr(p, \"text\"))\n",
    "                elif isinstance(p, dict) and isinstance(p.get(\"text\"), str):\n",
    "                    texts.append(p[\"text\"])\n",
    "            if texts:\n",
    "                return \"\\n\".join(texts)\n",
    "        if isinstance(c, str):\n",
    "            return c\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "def extract_last_text(events: List[Any]) -> str:\n",
    "    for e in reversed(events or []):\n",
    "        t = _event_to_text(e).strip()\n",
    "        if t:\n",
    "            return t\n",
    "    return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e458e885",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------\n",
    "# 4) Aggregation + ranking helpers\n",
    "# -----------------------\n",
    "def _norm_key(s: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", (s or \"\").strip().lower())\n",
    "\n",
    "def _paper_cite(p: dict) -> str:\n",
    "    title = p.get(\"title\") or \"(untitled)\"\n",
    "    authors = \", \".join(p.get(\"authors\") or []) or \"UNKNOWN\"\n",
    "    journal = p.get(\"journal\") or \"UNKNOWN JOURNAL\"\n",
    "    year = p.get(\"year\") or \"n.d.\"\n",
    "    doi = p.get(\"doi\")\n",
    "    doi_txt = f\", DOI: {doi}\" if doi else \"\"\n",
    "    return f\"{title} — {authors}. {journal} ({year}){doi_txt}\"\n",
    "\n",
    "def _polarity_weight(polarity: str) -> float:\n",
    "    polarity = (polarity or \"\").lower()\n",
    "    if polarity == \"supports\":\n",
    "        return 1.0\n",
    "    if polarity == \"mixed\":\n",
    "        return 0.6\n",
    "    if polarity == \"unclear\":\n",
    "        return 0.35\n",
    "    if polarity == \"refutes\":\n",
    "        return 0.2\n",
    "    return 0.35\n",
    "\n",
    "def aggregate_findings(papers: list) -> dict:\n",
    "    buckets = defaultdict(lambda: defaultdict(lambda: {\n",
    "        \"score\": 0.0,\n",
    "        \"count\": 0,\n",
    "        \"papers\": set(),\n",
    "        \"snippets\": [],\n",
    "        \"polarities\": Counter(),\n",
    "    }))\n",
    "\n",
    "    for p in papers:\n",
    "        pscore = float(p.get(\"relevance_score\") or 0.0)\n",
    "        cite = _paper_cite(p)\n",
    "\n",
    "        for f in (p.get(\"findings\") or []):\n",
    "            cat = (f.get(\"category\") or \"other\").lower()\n",
    "            name = (f.get(\"name\") or \"\").strip()\n",
    "            if not name:\n",
    "                continue\n",
    "            key = _norm_key(name)\n",
    "\n",
    "            pol = (f.get(\"polarity\") or \"unclear\").lower()\n",
    "            w = _polarity_weight(pol)\n",
    "            score_add = w * (0.75 + 0.25 * min(1.0, pscore))\n",
    "\n",
    "            entry = buckets[cat][key]\n",
    "            entry[\"score\"] += score_add\n",
    "            entry[\"count\"] += 1\n",
    "            entry[\"papers\"].add(cite)\n",
    "            entry[\"polarities\"][pol] += 1\n",
    "\n",
    "            snip = (f.get(\"snippet\") or \"\").strip()\n",
    "            if snip:\n",
    "                entry[\"snippets\"].append({\"snippet\": snip, \"cite\": cite, \"polarity\": pol})\n",
    "\n",
    "    ranked = {}\n",
    "    for cat, items in buckets.items():\n",
    "        ranked_items = []\n",
    "        for key, v in items.items():\n",
    "            ranked_items.append({\n",
    "                \"name\": key,\n",
    "                \"score\": v[\"score\"],\n",
    "                \"mentions\": v[\"count\"],\n",
    "                \"papers\": sorted(v[\"papers\"]),\n",
    "                \"polarities\": v[\"polarities\"],\n",
    "                \"snippets\": v[\"snippets\"][:12],\n",
    "            })\n",
    "        ranked_items.sort(key=lambda x: (x[\"score\"], len(x[\"papers\"])), reverse=True)\n",
    "        ranked[cat] = ranked_items\n",
    "    return ranked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e1143b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------\n",
    "# 5) Agents\n",
    "# -----------------------\n",
    "METADATA_SYSTEM = \"\"\"You extract bibliographic metadata from the first pages of a biomedical paper.\n",
    "\n",
    "Return ONE valid JSON object ONLY with EXACTLY these keys:\n",
    "{\n",
    "  \"title\": \"...\",\n",
    "  \"authors\": [\"Last, First\", \"...\"],\n",
    "  \"year\": null,\n",
    "  \"journal\": null,\n",
    "  \"doi\": null\n",
    "}\n",
    "\n",
    "Rules:\n",
    "- If unsure, use null (or [] for authors).\n",
    "- Do not hallucinate.\n",
    "\"\"\"\n",
    "\n",
    "RELEVANCE_SYSTEM = \"\"\"You decide whether a paper is relevant to the CONDITION.\n",
    "\n",
    "Return ONE valid JSON object ONLY with EXACTLY these keys:\n",
    "{\n",
    "  \"paper_id\": \"...\",\n",
    "  \"title\": \"...\",\n",
    "  \"is_relevant\": false,\n",
    "  \"relevance_score\": 0.0,\n",
    "  \"reason\": \"...\",\n",
    "  \"matched_terms\": [\"...\", \"...\"]\n",
    "}\n",
    "\n",
    "Rules:\n",
    "- Use ONLY the provided text.\n",
    "- relevance_score is 0..1.\n",
    "- If uncertain, be conservative.\n",
    "\"\"\"\n",
    "\n",
    "EXTRACTION_SYSTEM = \"\"\"You extract structured findings from a paper for the CONDITION.\n",
    "\n",
    "Return ONE valid JSON object ONLY with EXACTLY these keys:\n",
    "{\n",
    "  \"paper_id\": \"...\",\n",
    "  \"title\": \"...\",\n",
    "  \"year\": null,\n",
    "  \"journal\": null,\n",
    "  \"condition\": \"...\",\n",
    "  \"relevance_score\": 0.0,\n",
    "  \"summary\": \"...\",\n",
    "  \"key_takeaways\": [\"...\", \"...\"],\n",
    "  \"findings\": [\n",
    "    {\"name\":\"...\", \"category\":\"definition|gene|symptom|treatment|outcome|population|other\",\n",
    "     \"polarity\":\"supports|refutes|mixed|unclear\",\n",
    "     \"snippet\":\"<=2 sentences\", \"section\":\"methods|results|discussion|abstract|unknown\"}\n",
    "  ]\n",
    "}\n",
    "\n",
    "Rules:\n",
    "- Use ONLY the provided text.\n",
    "- Do NOT invent details.\n",
    "- Keep snippets short (<=2 sentences).\n",
    "- Put gene names under category \"gene\" when possible.\n",
    "\"\"\"\n",
    "\n",
    "QA_SYSTEM = \"\"\"You are a biomedical literature Q&A agent.\n",
    "\n",
    "Answer ONLY using the evidence items you are given.\n",
    "If evidence does not contain the answer, say: \"Not found in the provided papers.\"\n",
    "\n",
    "Use inline citations like [1], [2] corresponding to evidence item IDs.\n",
    "\n",
    "Output Markdown:\n",
    "1) Answer\n",
    "2) Evidence (bullets with snippet + citation number)\n",
    "3) References (numbered: title, authors, journal, year; include DOI if present)\n",
    "\"\"\"\n",
    "\n",
    "REPORT_SYSTEM = \"\"\"You are generating a Genex Evidence Report for clinicians and families.\n",
    "\n",
    "You will be given:\n",
    "- Condition name\n",
    "- Paper-level citations (numbered)\n",
    "- Evidence items grouped by section (definition/genes/symptoms/treatments/outcomes/other)\n",
    "\n",
    "STRICT RULES:\n",
    "- Write a coherent synthesis, NOT a snippet dump.\n",
    "- Use ONLY the evidence provided. Do not add facts.\n",
    "- Weight language by strength of evidence (strong/moderate/limited).\n",
    "- Every key claim must have an inline citation like [1], [2].\n",
    "- If a section has insufficient evidence, say so.\n",
    "\n",
    "Write Markdown with sections:\n",
    "1) Executive Summary including definition and genes affected\n",
    "2) Symptoms supported by literature (ranked)\n",
    "3) Treatments/interventions supported by literature (ranked)\n",
    "4) Outcomes / prognosis (if present)\n",
    "5) Conflicting / uncertain areas\n",
    "6) Limitations + what to read next\n",
    "7) References (numbered list)\n",
    "\"\"\"\n",
    "\n",
    "metadata_agent = LlmAgent(name=\"PaperMetadataExtractor\", model=llm, instruction=METADATA_SYSTEM)\n",
    "relevance_agent = LlmAgent(name=\"PaperRelevanceScreener\", model=llm, instruction=RELEVANCE_SYSTEM)\n",
    "extraction_agent = LlmAgent(name=\"PaperExtractor\", model=llm, instruction=EXTRACTION_SYSTEM)\n",
    "qa_agent = LlmAgent(name=\"PaperQAAgent\", model=llm, instruction=QA_SYSTEM)\n",
    "report_agent = LlmAgent(name=\"GenexReportSynthesizer\", model=llm, instruction=REPORT_SYSTEM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1df8ce5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------\n",
    "# 6) Pipeline + report synthesis\n",
    "# -----------------------\n",
    "def infer_meta_from_text(paper_id: str, path: str, raw_text: str) -> Dict[str, Any]:\n",
    "    title = os.path.splitext(os.path.basename(path))[0]\n",
    "    year = None\n",
    "    m = re.search(r\"(19\\d{2}|20\\d{2})\", raw_text[:4000])\n",
    "    if m:\n",
    "        try:\n",
    "            year = int(m.group(1))\n",
    "        except Exception:\n",
    "            year = None\n",
    "    return {\n",
    "        \"paper_id\": paper_id,\n",
    "        \"path\": path,\n",
    "        \"title\": title,\n",
    "        \"year\": year,\n",
    "        \"journal\": None,\n",
    "        \"authors\": [],\n",
    "        \"doi\": None,\n",
    "    }\n",
    "\n",
    "async def extract_metadata(paper_id: str, path: str) -> Dict[str, Any]:\n",
    "    meta_text = pdf_to_text(path, max_pages=2)[:60000]\n",
    "    meta = infer_meta_from_text(paper_id, path, meta_text)\n",
    "\n",
    "    session_id = f\"meta-{paper_id}\"\n",
    "    await session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=session_id)\n",
    "    runner = Runner(app_name=APP_NAME, agent=metadata_agent, session_service=session_service)\n",
    "\n",
    "    msg = f\"\"\"PAPER_ID: {paper_id}\n",
    "FILENAME: {os.path.basename(path)}\n",
    "\n",
    "TEXT (first pages):\n",
    "{meta_text}\n",
    "\"\"\"\n",
    "    events = await run_runner(runner, user_id=USER_ID, session_id=session_id, text=msg)\n",
    "    meta_json = safe_json_extract(extract_last_text(events))\n",
    "\n",
    "    if isinstance(meta_json, dict):\n",
    "        meta[\"title\"] = meta_json.get(\"title\") or meta[\"title\"]\n",
    "        meta[\"journal\"] = meta_json.get(\"journal\") or meta[\"journal\"]\n",
    "        meta[\"year\"] = meta_json.get(\"year\") or meta[\"year\"]\n",
    "        meta[\"doi\"] = meta_json.get(\"doi\") or meta.get(\"doi\")\n",
    "        meta[\"authors\"] = meta_json.get(\"authors\") or meta.get(\"authors\", [])\n",
    "    return meta\n",
    "\n",
    "async def screen_relevance(condition: str, paper_id: str, title: str, text: str) -> RelevanceDecision:\n",
    "    session_id = f\"rel-{paper_id}\"\n",
    "    await session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=session_id)\n",
    "    runner = Runner(app_name=APP_NAME, agent=relevance_agent, session_service=session_service)\n",
    "\n",
    "    prompt = f\"\"\"CONDITION: {condition}\n",
    "PAPER_ID: {paper_id}\n",
    "TITLE: {title}\n",
    "\n",
    "TEXT:\n",
    "{text[:120000]}\n",
    "\"\"\"\n",
    "    events = await run_runner(runner, user_id=USER_ID, session_id=session_id, text=prompt)\n",
    "    obj = safe_json_extract(extract_last_text(events)) or {}\n",
    "    obj.setdefault(\"paper_id\", paper_id)\n",
    "    obj.setdefault(\"title\", title)\n",
    "    return RelevanceDecision(**obj)\n",
    "\n",
    "async def extract_paper(condition: str, paper_id: str, meta: Dict[str, Any], text: str, relevance_score: float) -> PaperExtraction:\n",
    "    session_id = f\"ext-{paper_id}\"\n",
    "    await session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=session_id)\n",
    "    runner = Runner(app_name=APP_NAME, agent=extraction_agent, session_service=session_service)\n",
    "\n",
    "    prompt = f\"\"\"CONDITION: {condition}\n",
    "PAPER_ID: {paper_id}\n",
    "TITLE: {meta.get('title')}\n",
    "YEAR: {meta.get('year')}\n",
    "JOURNAL: {meta.get('journal')}\n",
    "AUTHORS: {\", \".join(meta.get(\"authors\") or [])}\n",
    "DOI: {meta.get('doi')}\n",
    "\n",
    "TEXT:\n",
    "{text[:140000]}\n",
    "\"\"\"\n",
    "    events = await run_runner(runner, user_id=USER_ID, session_id=session_id, text=prompt)\n",
    "    obj = safe_json_extract(extract_last_text(events)) or {}\n",
    "\n",
    "    obj[\"paper_id\"] = paper_id\n",
    "    obj[\"title\"] = meta.get(\"title\") or obj.get(\"title\") or \"\"\n",
    "    obj[\"authors\"] = meta.get(\"authors\") or obj.get(\"authors\") or []\n",
    "    obj[\"year\"] = meta.get(\"year\") or obj.get(\"year\")\n",
    "    obj[\"journal\"] = meta.get(\"journal\") or obj.get(\"journal\")\n",
    "    obj[\"doi\"] = meta.get(\"doi\") or obj.get(\"doi\")\n",
    "    obj[\"condition\"] = condition\n",
    "    obj[\"relevance_score\"] = float(relevance_score or obj.get(\"relevance_score\") or 0.0)\n",
    "\n",
    "    if not isinstance(obj.get(\"findings\"), list):\n",
    "        obj[\"findings\"] = []\n",
    "    return PaperExtraction(**obj)\n",
    "\n",
    "def _collect_unique_references(papers: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "    seen = set()\n",
    "    refs = []\n",
    "    for p in papers:\n",
    "        cite = _paper_cite(p)\n",
    "        if cite in seen:\n",
    "            continue\n",
    "        seen.add(cite)\n",
    "        refs.append({\n",
    "            \"cite\": cite,\n",
    "            \"title\": p.get(\"title\"),\n",
    "            \"authors\": p.get(\"authors\") or [],\n",
    "            \"journal\": p.get(\"journal\"),\n",
    "            \"year\": p.get(\"year\"),\n",
    "            \"doi\": p.get(\"doi\"),\n",
    "        })\n",
    "    return refs\n",
    "\n",
    "def _select_evidence_items(ranked: dict, max_per_section: int = 18) -> Dict[str, List[Dict[str, Any]]]:\n",
    "    sections = {\n",
    "        \"definition\": ranked.get(\"definition\", [])[:max_per_section],\n",
    "        \"gene\": (ranked.get(\"gene\", []) + ranked.get(\"genes\", []))[:max_per_section],\n",
    "        \"symptom\": ranked.get(\"symptom\", [])[:max_per_section],\n",
    "        \"treatment\": ranked.get(\"treatment\", [])[:max_per_section],\n",
    "        \"outcome\": ranked.get(\"outcome\", [])[:max_per_section],\n",
    "        \"other\": ranked.get(\"other\", [])[:max_per_section],\n",
    "    }\n",
    "\n",
    "    out: Dict[str, List[Dict[str, Any]]] = {}\n",
    "    for sec, items in sections.items():\n",
    "        ev = []\n",
    "        for it in items:\n",
    "            for s in (it.get(\"snippets\") or [])[:2]:\n",
    "                ev.append({\n",
    "                    \"concept\": it.get(\"name\"),\n",
    "                    \"score\": float(it.get(\"score\") or 0.0),\n",
    "                    \"mentions\": int(it.get(\"mentions\") or 0),\n",
    "                    \"polarity\": s.get(\"polarity\") or \"unclear\",\n",
    "                    \"snippet\": s.get(\"snippet\") or \"\",\n",
    "                    \"cite\": s.get(\"cite\") or \"\",\n",
    "                })\n",
    "        out[sec] = ev\n",
    "    return out\n",
    "\n",
    "async def synthesize_report(condition: str, papers_screened: int, papers_relevant: int, papers: List[Dict[str, Any]], ranked: dict) -> str:\n",
    "    evidence_by_section = _select_evidence_items(ranked, max_per_section=18)\n",
    "    refs = _collect_unique_references(papers)\n",
    "\n",
    "    ref_id_map: Dict[str, int] = {}\n",
    "    numbered_refs = []\n",
    "    for i, r in enumerate(refs, start=1):\n",
    "        ref_id_map[r[\"cite\"]] = i\n",
    "        authors = \", \".join(r.get(\"authors\") or []) or \"UNKNOWN\"\n",
    "        journal = r.get(\"journal\") or \"UNKNOWN JOURNAL\"\n",
    "        year = r.get(\"year\") or \"n.d.\"\n",
    "        doi = r.get(\"doi\")\n",
    "        doi_txt = f\" doi: {doi}\" if doi else \"\"\n",
    "        numbered_refs.append(f\"[{i}] {r.get('title') or '(untitled)'}, {authors}, {journal}, {year}.{doi_txt}\")\n",
    "\n",
    "    def format_evidence(items: List[Dict[str, Any]], max_items: int = 40) -> str:\n",
    "        lines = []\n",
    "        for it in items[:max_items]:\n",
    "            rid = ref_id_map.get(it[\"cite\"])\n",
    "            rid_txt = f\"[{rid}]\" if rid is not None else \"[?]\"\n",
    "            lines.append(\n",
    "                f\"- concept='{it['concept']}', evidence_score={it['score']:.2f}, mentions={it['mentions']}, polarity={it['polarity']} {rid_txt}\\n\"\n",
    "                f\"  snippet: {it['snippet']}\"\n",
    "            )\n",
    "        return \"\\n\".join(lines) if lines else \"- (none)\"\n",
    "\n",
    "    prompt = \"\\n\\n\".join([\n",
    "        f\"CONDITION: {condition}\",\n",
    "        f\"PAPERS_SCREENED: {papers_screened}\",\n",
    "        f\"PAPERS_RELEVANT: {papers_relevant}\",\n",
    "        \"REFERENCES (use these ids for citations):\\n\" + \"\\n\".join(numbered_refs),\n",
    "        \"EVIDENCE ITEMS — definition:\\n\" + format_evidence(evidence_by_section.get(\"definition\", [])),\n",
    "        \"EVIDENCE ITEMS — genes:\\n\" + format_evidence(evidence_by_section.get(\"gene\", [])),\n",
    "        \"EVIDENCE ITEMS — symptoms:\\n\" + format_evidence(evidence_by_section.get(\"symptom\", [])),\n",
    "        \"EVIDENCE ITEMS — treatments:\\n\" + format_evidence(evidence_by_section.get(\"treatment\", [])),\n",
    "        \"EVIDENCE ITEMS — outcomes:\\n\" + format_evidence(evidence_by_section.get(\"outcome\", [])),\n",
    "        \"EVIDENCE ITEMS — other/notes:\\n\" + format_evidence(evidence_by_section.get(\"other\", [])),\n",
    "    ])\n",
    "\n",
    "    session_id = f\"report-{uuid.uuid4().hex[:8]}\"\n",
    "    await session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=session_id)\n",
    "    runner = Runner(app_name=APP_NAME, agent=report_agent, session_service=session_service)\n",
    "\n",
    "    events = await run_runner(runner, user_id=USER_ID, session_id=session_id, text=prompt)\n",
    "    return extract_last_text(events)\n",
    "\n",
    "async def run_condition_folder(condition: str, folder: str) -> Dict[str, Any]:\n",
    "    pdfs = list_pdfs(folder)\n",
    "    papers: List[Dict[str, Any]] = []\n",
    "    papers_screened = 0\n",
    "    papers_relevant = 0\n",
    "\n",
    "    for idx, path in enumerate(pdfs, start=1):\n",
    "        paper_id = f\"paper_{idx:03d}\"\n",
    "        raw_text = pdf_to_text(path, max_pages=MAX_PAGES_PER_PDF)\n",
    "        papers_screened += 1\n",
    "\n",
    "        meta = await extract_metadata(paper_id, path)\n",
    "        rel = await screen_relevance(condition, paper_id, meta.get(\"title\") or paper_id, raw_text)\n",
    "\n",
    "        if not rel.is_relevant or rel.relevance_score < 0.20:\n",
    "            continue\n",
    "\n",
    "        papers_relevant += 1\n",
    "        extraction = await extract_paper(condition, paper_id, meta, raw_text, rel.relevance_score)\n",
    "        papers.append(extraction.model_dump())\n",
    "\n",
    "    ranked = aggregate_findings(papers)\n",
    "\n",
    "    report_markdown = await synthesize_report(\n",
    "        condition=condition,\n",
    "        papers_screened=papers_screened,\n",
    "        papers_relevant=papers_relevant,\n",
    "        papers=papers,\n",
    "        ranked=ranked,\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"condition\": condition,\n",
    "        \"papers_screened\": papers_screened,\n",
    "        \"papers_relevant\": papers_relevant,\n",
    "        \"papers\": papers,\n",
    "        \"ranked\": ranked,\n",
    "        \"report_markdown\": report_markdown,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c4cf8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------\n",
    "# 7) Q&A over extracted evidence (unique session per question)\n",
    "# -----------------------\n",
    "def build_evidence_index(papers: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "    rows = []\n",
    "    for p in papers:\n",
    "        for f in (p.get(\"findings\") or []):\n",
    "            rows.append({\n",
    "                \"paper_id\": p.get(\"paper_id\"),\n",
    "                \"title\": p.get(\"title\"),\n",
    "                \"authors\": p.get(\"authors\") or [],\n",
    "                \"year\": p.get(\"year\"),\n",
    "                \"journal\": p.get(\"journal\"),\n",
    "                \"doi\": p.get(\"doi\"),\n",
    "                \"condition\": p.get(\"condition\"),\n",
    "                \"relevance_score\": p.get(\"relevance_score\", 0.0),\n",
    "                \"name\": f.get(\"name\"),\n",
    "                \"category\": f.get(\"category\"),\n",
    "                \"polarity\": f.get(\"polarity\"),\n",
    "                \"section\": f.get(\"section\"),\n",
    "                \"snippet\": f.get(\"snippet\"),\n",
    "            })\n",
    "    return rows\n",
    "\n",
    "def _tokenize(s: str) -> List[str]:\n",
    "    return re.findall(r\"[a-z0-9]+\", (s or \"\").lower())\n",
    "\n",
    "def retrieve_evidence(question: str, evidence_rows: List[Dict[str, Any]], top_k: int = 14) -> List[Dict[str, Any]]:\n",
    "    qtok = set(_tokenize(question))\n",
    "    if not qtok:\n",
    "        return evidence_rows[:top_k]\n",
    "\n",
    "    scored = []\n",
    "    for r in evidence_rows:\n",
    "        blob = \" \".join([\n",
    "            str(r.get(\"name\",\"\")),\n",
    "            str(r.get(\"category\",\"\")),\n",
    "            str(r.get(\"snippet\",\"\")),\n",
    "            str(r.get(\"title\",\"\")),\n",
    "            str(r.get(\"journal\",\"\")),\n",
    "        ]).lower()\n",
    "        btok = set(_tokenize(blob))\n",
    "        overlap = len(qtok & btok)\n",
    "        boost = 0.0\n",
    "        if (r.get(\"polarity\") or \"\").lower() == \"supports\":\n",
    "            boost += 0.25\n",
    "        boost += 0.15 * float(r.get(\"relevance_score\") or 0.0)\n",
    "        score = overlap + boost\n",
    "        if overlap > 0:\n",
    "            scored.append((score, r))\n",
    "\n",
    "    scored.sort(key=lambda x: x[0], reverse=True)\n",
    "    return [r for _, r in scored[:top_k]]\n",
    "\n",
    "async def ask_papers(question: str, result: Dict[str, Any], top_k: int = 14) -> str:\n",
    "    papers = result.get(\"papers\") or []\n",
    "    evidence_rows = build_evidence_index(papers)\n",
    "    top = retrieve_evidence(question, evidence_rows, top_k=top_k)\n",
    "\n",
    "    lines = []\n",
    "    for i, r in enumerate(top, start=1):\n",
    "        authors = \", \".join(r.get(\"authors\") or [])\n",
    "        lines.append(\n",
    "            f\"\"\"EVIDENCE_ITEM [{i}]\n",
    "paper_id: {r.get('paper_id')}\n",
    "title: {r.get('title')}\n",
    "authors: {authors if authors else 'UNKNOWN'}\n",
    "journal: {r.get('journal')}\n",
    "year: {r.get('year')}\n",
    "doi: {r.get('doi')}\n",
    "category: {r.get('category')}\n",
    "name: {r.get('name')}\n",
    "polarity: {r.get('polarity')}\n",
    "section: {r.get('section')}\n",
    "snippet: {r.get('snippet')}\n",
    "\"\"\"\n",
    "        )\n",
    "\n",
    "    qa_context = \"\\n\".join(lines) if lines else \"NO EVIDENCE ITEMS RETRIEVED.\"\n",
    "\n",
    "    session_id = f\"qa-{uuid.uuid4().hex[:8]}\"\n",
    "    await session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=session_id)\n",
    "    runner = Runner(app_name=APP_NAME, agent=qa_agent, session_service=session_service)\n",
    "\n",
    "    prompt = f\"\"\"USER QUESTION:\n",
    "{question}\n",
    "\n",
    "{qa_context}\n",
    "\"\"\"\n",
    "    events = await run_runner(runner, user_id=USER_ID, session_id=session_id, text=prompt)\n",
    "    return extract_last_text(events)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad0b571c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------\n",
    "# 8) How to run (example)\n",
    "# -----------------------\n",
    "# If your notebook doesn't support top-level `await`, uncomment:\n",
    "# import nest_asyncio\n",
    "# nest_asyncio.apply()\n",
    "\n",
    "# result = await run_condition_folder(\"L-serine deficiency disorder\", PAPERS_DIR)\n",
    "# print(result[\"papers_screened\"], result[\"papers_relevant\"])\n",
    "# print(result[\"report_markdown\"][:4000])\n",
    "\n",
    "# Q&A examples:\n",
    "# print(await ask_papers(\"What genes are linked to serine deficiency disorder?\", result))\n",
    "# print(await ask_papers(\"Is there any therapy recommended?\", result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e03fa627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 6\n",
      "# Genex Evidence Report: L-serine Deficiency Disorder\n",
      "\n",
      "## 1) Executive Summary\n",
      "L-serine deficiency disorder encompasses a range of conditions resulting from primary defects in the synthesis of L-serine, crucial for neurological health. It includes a spectrum that ranges from prenatal lethal conditions, such as Neu-Laxova syndrome, to forms manifesting at various ages, including juvenile and adult onset [1], [6]. Genetic mutations contributing to this disorder primarily involve three genes: **PHGDH** (3-phosphoglycerate dehydrogenase), **PSAT1** (phosphoserine aminotransferase), and **PSPH** (phosphoserine phosphatase). Identifying biallelic pathogenic variants in these genes is essential for diagnosis and understanding the disorder's manifestation [1], [6].\n",
      "\n",
      "## 2) Symptoms Supported by Literature\n",
      "Symptoms associated with L-serine deficiency disorder, ranked by evidence strength, include:\n",
      "1. **Neu-Laxova Syndrome**: Characterized by severe intrauterine growth deficiency, microcephaly, congenital bilateral cataracts, and ichthyosis [1].\n",
      "2. **Progressive Axonal Polyneuropathy**: Particularly notable in adult-onset cases, it can involve ataxia and potential cognitive impairment [1].\n",
      "3. **Symptoms of PHGDH Deficiency**: Individuals may exhibit microcephaly, psychomotor retardation, and seizures [2].\n",
      "4. **Neuropathy Symptoms**: While treated individuals show slight improvements, substantial alleviation of neurologic impairments remains uncertain [4].\n",
      "\n",
      "## 3) Treatments/Interventions Supported by Literature\n",
      "Treatment options for L-serine deficiency disorder are primarily founded on L-serine supplementation, with the following hierarchy of evidence:\n",
      "1. **L-serine Supplementation**: Strong evidence supports its use as a therapeutic intervention, showing benefits in various neuropathic complications [1], [6].\n",
      "2. **High-Dose Oral L-serine**: This treatment has demonstrated complete resolution of ichthyosis and improved neurological alertness [5].\n",
      "3. **Neurological Improvements**: Reports indicate enhanced cognitive alertness and vocalization following therapy with L-serine [5].\n",
      "4. **Glycine Supplementation**: Used alongside L-serine in some cases to enhance therapeutic outcomes [1].\n",
      "\n",
      "## 4) Outcomes / Prognosis\n",
      "The prognosis for individuals treated with L-serine is generally positive when intervention occurs early:\n",
      "- **Normal Developmental Outcomes**: Patients who receive L-serine supplementation prenatally or shortly after birth may achieve normal development [1].\n",
      "- **Seizure Management**: Reduction in the frequency of seizures has been reported following treatment [3].\n",
      "- **Resolution of Ichthyosis**: Successful alleviation of skin lesions has been consistently documented [5].\n",
      "\n",
      "## 5) Conflicting / Uncertain Areas\n",
      "Despite many positive reports, certain symptoms remain challenging:\n",
      "- **Neurocognitive Impairment**: There is a lack of substantial improvement in cognitive functions for treated individuals, indicating that while some physical symptoms may be alleviated, cognitive deficits persist [3].\n",
      "\n",
      "## 6) Limitations + What to Read Next\n",
      "The findings primarily stem from a limited number of studies, which may not capture the full spectrum of L-serine deficiency disorders or the variability in clinical responses to treatment. Future reading should focus on larger cohort studies examining long-term outcomes and the broader impacts of L-serine supplementation on cognitive functions in diverse patient populations.\n",
      "\n",
      "## 7) References\n",
      "1. Serine Deficiency Disorders, van der Crabben, SN, de Koning, TJ, GeneReviews, 2023.\n",
      "2. Mild phenotypes of phosphoglycerate dehydrogenase deficiency by a novel mutation of PHGDH gene: Case report and literature review, Fu, Junyi, Chen, Liqing, Su, Tangfeng, Xu, Sanqing, Liu, Yan, International Journal of Developmental Neuroscience, 2022.\n",
      "3. Two new cases of serine deficiency disorders treated with l-serine, Brassier, A, Valayannopoulos, V, Bahi-Buisson, N, et al., Eur J Paediatr Neurol, 2016.\n",
      "4. Juvenile-onset PSAT1-r\n"
     ]
    }
   ],
   "source": [
    "result = await run_condition_folder(\"L-serine deficiency disorder\", PAPERS_DIR)\n",
    "print(result[\"papers_screened\"], result[\"papers_relevant\"])\n",
    "print(result[\"report_markdown\"][:4000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88ffc015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) The genes linked to serine deficiency disorder are **PHGDH**, **PSAT1**, and **PSPH**.\n",
      "\n",
      "2) Evidence:\n",
      "   - \"The diagnosis of a serine deficiency disorder is established in a proband with biallelic pathogenic variants in **PHGDH, PSAT1, or PSPH** identified by molecular genetic testing.\" [2]\n",
      "   - \"Patient 1 had serine deficiency due to **3-phosphoglycerate dehydrogenase (PHGDH)** deficiency.\" [3]\n",
      "   - \"Patient 2 had serine deficiency due to **phosphoserine aminotransferase (PSAT1)** deficiency.\" [4]\n",
      "\n",
      "3) References:\n",
      "1. Serine Deficiency Disorders; van der Crabben, SN, de Koning, TJ; GeneReviews; 2023.\n",
      "2. Two new cases of serine deficiency disorders treated with l-serine; Brassier, A, Valayannopoulos, V, et al.; Eur J Paediatr Neurol; 2016; DOI: 10.1016/j.ejpn.2015.10.007.\n"
     ]
    }
   ],
   "source": [
    "print(await ask_papers(\"What genes are linked to serine deficiency disorder?\", result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ac8bc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Not found in the provided papers.\n",
      "\n",
      "2) \n",
      "- \"Neu-Laxova syndrome is characterized by severe intrauterine growth deficiency, microcephaly, congenital bilateral cataracts, characteristic dysmorphic features, limb anomalies, and collodion-like ichthyosis.\" [1]\n",
      "- \"The diagnosis of a serine deficiency disorder is established in a proband with biallelic pathogenic variants in PHGDH, PSAT1, or PSPH identified by molecular genetic testing.\" [2]\n",
      "- \"Adult-onset serine deficiency is characterized by progressive axonal polyneuropathy with ataxia and possible cognitive impairment.\" [3]\n",
      "\n",
      "3) \n",
      "1. Serine Deficiency Disorders, van der Crabben, SN, de Koning, TJ, GeneReviews, 2023.\n"
     ]
    }
   ],
   "source": [
    "print(await ask_papers(\"Is there any therapy recommended?\", result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87beea06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Answer  \n",
      "A baby can develop serine deficiency due to genetic factors that influence its metabolism, such as biallelic pathogenic variants in genes like PHGDH, PSAT1, or PSPH, which play critical roles in serine biosynthesis [2]. Additionally, reduced serine levels can be observed in fetal cord blood, indicating that the deficiency may arise during pregnancy [14].\n",
      "\n",
      "2) Evidence  \n",
      "- \"The diagnosis of a serine deficiency disorder is established in a proband with biallelic pathogenic variants in PHGDH, PSAT1, or PSPH identified by molecular genetic testing.\" [2]  \n",
      "- \"Reduced serine levels in fetal cord blood may also be diagnostic as early as 30 weeks of pregnancy.\" [14]  \n",
      "\n",
      "3) References  \n",
      "1. Serine Deficiency Disorders, van der Crabben, SN, de Koning, TJ, GeneReviews, 2023.  \n",
      "2. Two new cases of serine deficiency disorders treated with l-serine, Brassier, A et al., Eur J Paediatr Neurol, 2016; DOI: 10.1016/j.ejpn.2015.10.007.  \n",
      "3. Juvenile-onset PSAT1-related neuropathy: A milder phenotype of serine deficiency disorder, Shen, Yu et al., Frontiers in Genetics, 2022; DOI: 10.3389/fgene.2022.949038.  \n",
      "4. Mild phenotypes of phosphoglycerate dehydrogenase deficiency by a novel mutation of PHGDH gene: Case report and literature review, Fu, Junyi et al., International Journal of Developmental Neuroscience, 2022; DOI: 10.1002/jdn.10236.  \n",
      "5. Serine Metabolism in Health and Disease and as a Conditionally Essential Amino Acid, Holeˇcek, Milan, Nutrients, 2022; DOI: 10.3390/nu14091987.\n"
     ]
    }
   ],
   "source": [
    "print(await ask_papers(\"How a baby gets serine deficiency?\", result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5366e2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) If both parents have one copy of any gene related to serine deficiency mutation on the same copy, the offspring may have a risk of inheriting homozygous mutations, leading to serine deficiency disorders. Such disorders can manifest in various clinical phenotypes, including potential neurological and cognitive impairments.\n",
      "\n",
      "2) Evidence:\n",
      "- \"A homozygous variant c.43G > C (p.A15P) in the PSAT1 gene was identified in both patients.\" [1]\n",
      "- \"Serine deficiency disorders include a spectrum of disease ranging from lethal prenatal-onset Neu-Laxova syndrome to serine deficiency with infantile, juvenile, or adult onset.\" [6]\n",
      "- \"The diagnosis of a serine deficiency disorder is established in a proband with biallelic pathogenic variants in PHGDH, PSAT1, or PSPH identified by molecular genetic testing.\" [7]\n",
      "\n",
      "3) References:\n",
      "1. Juvenile-onset PSAT1-related neuropathy: A milder phenotype of serine deﬁciency disorder, Shen, Yu et al., Frontiers in Genetics, 2022; DOI: 10.3389/fgene.2022.949038\n",
      "2. Serine Deficiency Disorders, van der Crabben, SN & de Koning, TJ, GeneReviews, 2023; DOI: None\n",
      "3. Serine Deficiency Disorders, van der Crabben, SN & de Koning, TJ, GeneReviews, 2023; DOI: None\n"
     ]
    }
   ],
   "source": [
    "print(await ask_papers(\"What if both parents have one copy of any of genese related to serine deficiency mutation on the same copy?\", result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb151592",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
