{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {},
  "cells": [
    {
      "id": "0fcae33b",
      "cell_type": "markdown",
      "source": "\n# HPO / Orphadata \u2014 Quick EDA\n\nThis notebook loads the processed tables from `data_proc/` and produces quick summaries and plots.\nIt also **saves** CSV previews and figures into `data_proc/_previews/` so you can open them later.\n\n**What it expects to find** (after you run `build_tables` and `make_matrices`):\n\n- `data_proc/condition.parquet`\n- `data_proc/feature.parquet`\n- `data_proc/condition_feature.parquet`\n- (optional) `data_proc/X_hpo_csr.npz` and `data_proc/mappings.json`\n\n> Tip: You can run this from anywhere; it will search upward for a `data_proc/` folder.\n",
      "metadata": {}
    },
    {
      "id": "375b820e",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\nfrom pathlib import Path\nimport json\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# ---- Find repo root by locating data_proc/\ndef find_data_proc(start: Path = Path.cwd(), max_up: int = 6) -> Path:\n    cur = start.resolve()\n    for _ in range(max_up):\n        dp = cur / \"data_proc\"\n        if dp.exists() and dp.is_dir():\n            return dp\n        cur = cur.parent\n    return (start / \"data_proc\").resolve()\n\nDP = find_data_proc()\nDP\n",
      "outputs": []
    },
    {
      "id": "155110d7",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\ndef _safe_read_parquet(p: Path):\n    if p.exists():\n        try:\n            return pd.read_parquet(p)\n        except Exception as e:\n            print(f\"Failed to read {p}: {e}\")\n    else:\n        print(f\"Missing file: {p}\")\n    return None\n\nCOND_F = DP / \"condition.parquet\"\nFEAT_F = DP / \"feature.parquet\"\nCF_F   = DP / \"condition_feature.parquet\"\n\ncond = _safe_read_parquet(COND_F)\nfeat = _safe_read_parquet(FEAT_F)\ncf   = _safe_read_parquet(CF_F)\n\nprint('Loaded:')\nfor name, df in [('condition', cond), ('feature', feat), ('condition_feature', cf)]:\n    print(f'  {name:18s}:', 'MISSING' if df is None else df.shape)\n",
      "outputs": []
    },
    {
      "id": "dfaee65a",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\ndef preview(df, name, n=5):\n    if df is None:\n        print(f\"[{name}] missing\")\n        return\n    print(f\"=== {name.upper()} (shape={df.shape}) ===\")\n    display(df.head(n))\n\npreview(cond, \"condition\")\npreview(feat, \"feature\")\npreview(cf, \"condition_feature\")\n",
      "outputs": []
    },
    {
      "id": "15824963",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\nPREV = DP / \"_previews\"\nPREV.mkdir(parents=True, exist_ok=True)\n\ndef _save_head(df, path: Path, n=200):\n    if df is None: \n        return\n    try:\n        df.head(n).to_csv(path, index=False)\n        print(\"Saved:\", path)\n    except Exception as e:\n        print(\"Failed to save\", path, \"->\", e)\n\n_save_head(cond, PREV / \"preview_condition.csv\")\n_save_head(feat, PREV / \"preview_feature.csv\")\n_save_head(cf,   PREV / \"preview_condition_feature.csv\")\n",
      "outputs": []
    },
    {
      "id": "ec66fa04",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\ndef null_summary(df, name):\n    if df is None:\n        return pd.DataFrame([{\"table\": name, \"column\": \"<missing>\", \"dtype\": None, \"n_null\": None, \"pct_null\": None, \"n_unique\": None}])\n    rows = []\n    for c in df.columns:\n        n_null = int(df[c].isna().sum())\n        pct = (n_null / len(df)) if len(df) else 0.0\n        nunq = int(df[c].nunique(dropna=True))\n        rows.append({\"table\": name, \"column\": c, \"dtype\": str(df[c].dtype), \"n_null\": n_null, \"pct_null\": pct, \"n_unique\": nunq})\n    out = pd.DataFrame(rows).sort_values([\"table\",\"column\"])\n    display(out)\n    return out\n\nns_cond = null_summary(cond, \"condition\")\nns_feat = null_summary(feat, \"feature\")\nns_cf   = null_summary(cf,   \"condition_feature\")\n\nall_ns = pd.concat([ns_cond, ns_feat, ns_cf], ignore_index=True)\nall_ns.to_csv(PREV / \"nulls_all.csv\", index=False)\nns_cond.to_csv(PREV / \"nulls_condition.csv\", index=False)\nns_feat.to_csv(PREV / \"nulls_feature.csv\", index=False)\nns_cf.to_csv(PREV / \"nulls_condition_feature.csv\", index=False)\nprint(\"Saved null CSVs in\", PREV)\n",
      "outputs": []
    },
    {
      "id": "4fbdacde",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\nif cf is not None and feat is not None:\n    freq = cf.groupby(\"feature_id\").size().sort_values(ascending=False).reset_index(name=\"n_conditions\")\n    feat_lbl = feat[[\"feature_id\",\"label\"]].drop_duplicates()\n    top = freq.head(30).merge(feat_lbl, on=\"feature_id\", how=\"left\")\n    top[\"label_fallback\"] = top[\"label\"].fillna(top[\"feature_id\"])\n    display(top[[\"feature_id\",\"label_fallback\",\"n_conditions\"]])\n\n    plt.figure()\n    plt.bar(top[\"label_fallback\"].astype(str), top[\"n_conditions\"].astype(int))\n    plt.title(\"Top HPO features by number of linked conditions\")\n    plt.xticks(rotation=90)\n    plt.tight_layout()\n    plt.show()\n\n    out = PREV / \"plot_top_hpo.png\"\n    plt.figure()\n    plt.bar(top[\"label_fallback\"].astype(str), top[\"n_conditions\"].astype(int))\n    plt.title(\"Top HPO features by number of linked conditions\")\n    plt.xticks(rotation=90)\n    plt.tight_layout()\n    plt.savefig(out, dpi=160, bbox_inches=\"tight\")\n    print(\"Saved:\", out)\nelse:\n    print(\"Skip: cf or feat missing\")\n",
      "outputs": []
    },
    {
      "id": "e5645c0d",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\nif feat is not None and \"ic\" in feat.columns:\n    vals = feat[\"ic\"].dropna().values\n    plt.figure()\n    plt.hist(vals, bins=40)\n    plt.title(\"HPO Information Content (IC) distribution\")\n    plt.xlabel(\"IC\")\n    plt.ylabel(\"Count\")\n    plt.tight_layout()\n    plt.show()\n\n    out = PREV / \"plot_ic_hist.png\"\n    plt.figure()\n    plt.hist(vals, bins=40)\n    plt.title(\"HPO Information Content (IC) distribution\")\n    plt.xlabel(\"IC\")\n    plt.ylabel(\"Count\")\n    plt.tight_layout()\n    plt.savefig(out, dpi=160, bbox_inches=\"tight\")\n    print(\"Saved:\", out)\nelse:\n    print(\"Skip: feature.ic missing\")\n",
      "outputs": []
    },
    {
      "id": "018a964a",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\nif cf is not None and cond is not None:\n    per = cf.groupby(\"condition_id\").size().rename(\"n_features\").reset_index()\n    plt.figure()\n    plt.hist(per[\"n_features\"].values, bins=40)\n    plt.title(\"Number of HPO features per condition\")\n    plt.xlabel(\"# HPO terms\")\n    plt.ylabel(\"Count of conditions\")\n    plt.tight_layout()\n    plt.show()\n\n    out = PREV / \"plot_features_per_condition.png\"\n    plt.figure()\n    plt.hist(per[\"n_features\"].values, bins=40)\n    plt.title(\"Number of HPO features per condition\")\n    plt.xlabel(\"# HPO terms\")\n    plt.ylabel(\"Count of conditions\")\n    plt.tight_layout()\n    plt.savefig(out, dpi=160, bbox_inches=\"tight\")\n    print(\"Saved:\", out)\nelse:\n    print(\"Skip: cf or cond missing\")\n",
      "outputs": []
    },
    {
      "id": "bc4ed8ed",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\nif cond is not None and \"category\" in cond.columns:\n    vc = cond[\"category\"].dropna().astype(str).value_counts().head(20)\n    if len(vc) > 0:\n        plt.figure()\n        plt.bar(vc.index.astype(str), vc.values.astype(int))\n        plt.title(\"Top categories (Orphadata/ORDO-derived)\")\n        plt.xticks(rotation=45)\n        plt.tight_layout()\n        plt.show()\n\n        out = PREV / \"plot_categories.png\"\n        plt.figure()\n        plt.bar(vc.index.astype(str), vc.values.astype(int))\n        plt.title(\"Top categories (Orphadata/ORDO-derived)\")\n        plt.xticks(rotation=45)\n        plt.tight_layout()\n        plt.savefig(out, dpi=160, bbox_inches=\"tight\")\n        print(\"Saved:\", out)\n    else:\n        print(\"category column present but empty\")\nelse:\n    print(\"Skip: category not present\")\n\nif cond is not None and \"prevalence_band\" in cond.columns:\n    pv = cond[\"prevalence_band\"].dropna().astype(str).value_counts()\n    if len(pv) > 0:\n        plt.figure()\n        plt.bar(pv.index.astype(str), pv.values.astype(int))\n        plt.title(\"Prevalence bands (if parsed)\")\n        plt.xticks(rotation=0)\n        plt.tight_layout()\n        plt.show()\n\n        out = PREV / \"plot_prevalence_bands.png\"\n        plt.figure()\n        plt.bar(pv.index.astype(str), pv.values.astype(int))\n        plt.title(\"Prevalence bands (if parsed)\")\n        plt.xticks(rotation=0)\n        plt.tight_layout()\n        plt.savefig(out, dpi=160, bbox_inches=\"tight\")\n        print(\"Saved:\", out)\n    else:\n        print(\"prevalence_band column present but empty\")\nelse:\n    print(\"Skip: prevalence_band not present\")\n\nif cond is not None and \"inheritance\" in cond.columns:\n    inh = cond[\"inheritance\"].dropna().astype(str).value_counts().head(15)\n    if len(inh) > 0:\n        plt.figure()\n        plt.bar(inh.index.astype(str), inh.values.astype(int))\n        plt.title(\"Top inheritance modes (if parsed)\")\n        plt.xticks(rotation=45)\n        plt.tight_layout()\n        plt.show()\n\n        out = PREV / \"plot_inheritance.png\"\n        plt.figure()\n        plt.bar(inh.index.astype(str), inh.values.astype(int))\n        plt.title(\"Top inheritance modes (if parsed)\")\n        plt.xticks(rotation=45)\n        plt.tight_layout()\n        plt.savefig(out, dpi=160, bbox_inches=\"tight\")\n        print(\"Saved:\", out)\n    else:\n        print(\"inheritance column present but empty\")\nelse:\n    print(\"Skip: inheritance not present\")\n",
      "outputs": []
    },
    {
      "id": "05d637ca",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\nfrom scipy.sparse import load_npz\n\nX_F   = DP / \"X_hpo_csr.npz\"\nMAP_F = DP / \"mappings.json\"\n\nif X_F.exists() and MAP_F.exists():\n    X = load_npz(X_F)\n    meta = json.loads(MAP_F.read_text(encoding=\"utf-8\"))\n    print(\"Matrix:\", X.shape, \"nnz=\", X.nnz)\n    print(\"Meta keys:\", list(meta.keys()))\n    density = X.nnz / (X.shape[0] * X.shape[1]) if X.shape[0] and X.shape[1] else 0.0\n\n    # save a tiny bar chart of density\n    plt.figure()\n    plt.bar([\"density\"], [density])\n    plt.title(\"Matrix density (nnz / total cells)\")\n    plt.tight_layout()\n    plt.show()\n\n    (PREV / \"matrix_info.txt\").write_text(f\"shape={X.shape}, nnz={X.nnz}, density={density:.6f}\", encoding=\"utf-8\")\n    plt.savefig(PREV / \"plot_matrix_density.png\", dpi=160, bbox_inches=\"tight\")\n    print(\"Saved matrix info and plot in\", PREV)\nelse:\n    print(\"Skip: X_hpo_csr.npz or mappings.json missing\")\n",
      "outputs": []
    }
  ]
}